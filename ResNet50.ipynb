{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jyvQUouwF2Tn22a2ZghmXYx5NyaDkHuW",
      "authorship_tag": "ABX9TyPzGackcj8AVd3Xq93hez8g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashrikant39/Histopatgology-Image-Classification/blob/main/ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOnzBnai_RVp"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision\r\n",
        "from torchsummary import summary\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import math\r\n",
        "import cv2"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm62yiRGGzFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffac09c-c9c5-4ee0-f2c9-d2011dcb63e9"
      },
      "source": [
        "!pip install pkbar\r\n",
        "import pkbar"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pkbar in /usr/local/lib/python3.6/dist-packages (0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pkbar) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVoBgr3YAP9v"
      },
      "source": [
        "batch_size= 32\r\n",
        "device = 'cuda'\r\n",
        "num_classes= 4\r\n",
        "input_shape=(3,224,224)\r\n",
        "layers= [3,4,6,3]\r\n",
        "learning_rate=5e-6\r\n",
        "num_epochs= 100"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao3vjZ8nfaRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dae50d9-01e6-4e16-fbc6-4fb793f4c0c1"
      },
      "source": [
        "main_path= 'drive/My Drive/Hist_folder/KMC Dataset'\r\n",
        "train_dir= os.path.join(main_path,'Training')\r\n",
        "test_dir= os.path.join(main_path,'Test')\r\n",
        "val_dir= os.path.join(main_path,'Validation')\r\n",
        "\r\n",
        "check_pt_file= os.path.join(main_path, 'ResNet50_Checkpoint_6.pth.tar')\r\n",
        "\r\n",
        "print(os.listdir(main_path))\r\n",
        "print(os.listdir(train_dir))\r\n",
        "print(os.listdir(test_dir))\r\n",
        "print(os.listdir(val_dir))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Training', 'Validation', 'Test', 'ResNet50_Checkpoint_1.pth.tar', 'AlexNet.ipynb', 'AlexNet_checkpoint.pth.tar', 'DenseNet.ipynb', 'ResNet50_Checkpoint_2.pth.tar', 'ResNet50_Checkpoint_3.pth.tar', 'ResNet50_Checkpoint_4.pth.tar', 'ResNet50.ipynb', 'ResNet50_Checkpoint_5.pth.tar', 'ResNet50_Checkpoint_6.pth.tar']\n",
            "['grade1', 'grade3', 'grade2', 'grade0']\n",
            "['grade1', 'grade0', 'grade2', 'grade3']\n",
            "['grade2', 'grade1', 'grade0', 'grade3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSDTwhDqOG8m"
      },
      "source": [
        "my_transforms = transforms.Compose([ #Compose makes it possible to have many transforms\r\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3), # Change brightness of image\r\n",
        "    transforms.RandomRotation(degrees=60), # Perhaps a random rotation from -45 to 45 degrees\r\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # Flips the image horizontally with probability 0.5\r\n",
        "    transforms.RandomVerticalFlip(p=0.05), # Flips image vertically with probability 0.05\r\n",
        "    transforms.ToTensor() # Finally converts PIL image to tensor so we can train w. pytorch\r\n",
        "    ])\r\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x2vEw-Tf_vk"
      },
      "source": [
        "train_data= datasets.ImageFolder(train_dir, transform= my_transforms)\r\n",
        "test_data= datasets.ImageFolder(test_dir, transform= transforms.ToTensor())\r\n",
        "val_data= datasets.ImageFolder(val_dir, transform= transforms.ToTensor())"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEDaY7p9gsEz"
      },
      "source": [
        "train_loader= DataLoader(train_data, batch_size=batch_size, shuffle=True)\r\n",
        "test_loader= DataLoader(test_data, batch_size=batch_size, shuffle=True)\r\n",
        "val_loader= DataLoader(val_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCHEpxdooz1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875d9ee3-8986-4855-b8d7-234de632b14d"
      },
      "source": [
        "class_dict=train_data.class_to_idx\r\n",
        "class_labels = class_dict.values()\r\n",
        "print(class_labels)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_values([0, 1, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWJYfR16O-0l"
      },
      "source": [
        "### Plotting the images with classes\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIA-Bc-iKHT"
      },
      "source": [
        "# iterator= iter(train_loader)\r\n",
        "# it= next(iterator)\r\n",
        "# images, labels= it\r\n",
        "\r\n",
        "# plt.figure(figsize=(20,15))\r\n",
        "# for r in range(batch_size):\r\n",
        "#     plt.subplot(4,8,r+1)\r\n",
        "#     f= plt.imshow(images[r].permute(2,1,0))\r\n",
        "#     plt.title(labels[r].item())\r\n",
        "# plt.show()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAbIU50Q_u2J"
      },
      "source": [
        "class Residual_Block(nn.Module):\r\n",
        "  def __init__(self, in_channels, out_channels, identity_downsample= None, stride=1):\r\n",
        "    super(Residual_Block,self).__init__()\r\n",
        "    self.expn= 4\r\n",
        "    self.conv1= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\r\n",
        "    self.bn1= nn.BatchNorm2d(num_features=out_channels)\r\n",
        "    self.conv2= nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1)\r\n",
        "    self.bn2= nn.BatchNorm2d(num_features=out_channels)\r\n",
        "    self.conv3= nn.Conv2d(in_channels= out_channels, out_channels=out_channels*self.expn, kernel_size=1, stride=1, padding=0)\r\n",
        "    self.bn3= nn.BatchNorm2d(num_features=out_channels*self.expn)\r\n",
        "    self.relu= nn.ReLU()\r\n",
        "    self.identity_downsample= identity_downsample\r\n",
        "\r\n",
        "  def forward(self,x):\r\n",
        "\r\n",
        "    identity=x\r\n",
        "    x= nn.Sequential(self.conv1,\r\n",
        "                     self.bn1,\r\n",
        "                     self.conv2,\r\n",
        "                     self.bn2,\r\n",
        "                     self.conv3,\r\n",
        "                     self.bn3)(x)\r\n",
        "    if self.identity_downsample is not None:\r\n",
        "      identity= self.identity_downsample(identity)\r\n",
        "    \r\n",
        "    x-= identity\r\n",
        "    x=self.relu(x)\r\n",
        "    \r\n",
        "    return x"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu3tkRKc_0Uw"
      },
      "source": [
        "class ResNet(nn.Module):\r\n",
        "  def __init__(self, Residual_Block, layers, image_channels, num_classes):\r\n",
        "    super(ResNet,self).__init__()\r\n",
        "    self.in_channels=64\r\n",
        "    self.conv1= nn.Conv2d(in_channels=image_channels, out_channels=64, kernel_size=7, stride=2, padding=3)\r\n",
        "    self.bn1= nn.BatchNorm2d(num_features= 64)\r\n",
        "    self.relu= nn.ReLU()\r\n",
        "    self.maxpool= nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "\r\n",
        "    self.layer_1= self._make_layer(Residual_Block, layers[0], out_channels=64, stride=1)\r\n",
        "    self.layer_2= self._make_layer(Residual_Block, layers[1], out_channels=128, stride=2)\r\n",
        "    self.layer_3= self._make_layer(Residual_Block, layers[2], out_channels=256, stride=2)\r\n",
        "    self.layer_4= self._make_layer(Residual_Block, layers[3], out_channels=512, stride=2)\r\n",
        "\r\n",
        "    self.avgpool= nn.AdaptiveAvgPool2d((1,1))\r\n",
        "    self.fc= nn.Linear(512*4, num_classes)\r\n",
        "\r\n",
        "  def forward(self,x):\r\n",
        "    x= nn.Sequential(self.conv1,\r\n",
        "                         self.bn1,\r\n",
        "                         self.relu,\r\n",
        "                         self.maxpool,\r\n",
        "                         self.layer_1,\r\n",
        "                         self.layer_2,\r\n",
        "                         self.layer_3,\r\n",
        "                         self.layer_4,\r\n",
        "                         self.avgpool)(x)\r\n",
        "    x= x.reshape(x.shape[0], -1)\r\n",
        "    x= self.fc(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "  def _make_layer(self,Residual_Block, num_res_blocks, out_channels, stride):\r\n",
        "    identity_downsample= None\r\n",
        "    layers=[]\r\n",
        "\r\n",
        "    if stride!=1 or self.in_channels!=out_channels*4:\r\n",
        "      identity_downsample= nn.Sequential(nn.Conv2d(in_channels=self.in_channels,\r\n",
        "                                                   out_channels= out_channels*4,\r\n",
        "                                                   kernel_size=1,\r\n",
        "                                                   stride=stride),\r\n",
        "                                         nn.BatchNorm2d(out_channels*4))\r\n",
        "    layers.append(Residual_Block(self.in_channels, out_channels, identity_downsample, stride))\r\n",
        "    self.in_channels= out_channels*4\r\n",
        "\r\n",
        "    for i in range(num_res_blocks-1):\r\n",
        "      layers.append(Residual_Block(self.in_channels, out_channels))\r\n",
        "    return nn.Sequential(*layers)\r\n",
        "\r\n",
        "  "
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJMSZVYzAOsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b552601-811c-4a8e-fdbe-f9f9cf160814"
      },
      "source": [
        "def ResNet50(img_channels=3, num_classes=10):\r\n",
        "  return ResNet(Residual_Block, layers, img_channels, num_classes)\r\n",
        "\r\n",
        "model= ResNet50(img_channels=input_shape[0], num_classes=num_classes).to(device)\r\n",
        "summary(model, input_size= input_shape, batch_size=batch_size, device=device)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [32, 64, 112, 112]           9,472\n",
            "       BatchNorm2d-2         [32, 64, 112, 112]             128\n",
            "              ReLU-3         [32, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [32, 64, 56, 56]               0\n",
            "            Conv2d-5           [32, 64, 56, 56]           4,160\n",
            "       BatchNorm2d-6           [32, 64, 56, 56]             128\n",
            "            Conv2d-7           [32, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-8           [32, 64, 56, 56]             128\n",
            "            Conv2d-9          [32, 256, 56, 56]          16,640\n",
            "      BatchNorm2d-10          [32, 256, 56, 56]             512\n",
            "           Conv2d-11          [32, 256, 56, 56]          16,640\n",
            "      BatchNorm2d-12          [32, 256, 56, 56]             512\n",
            "             ReLU-13          [32, 256, 56, 56]               0\n",
            "   Residual_Block-14          [32, 256, 56, 56]               0\n",
            "           Conv2d-15           [32, 64, 56, 56]          16,448\n",
            "      BatchNorm2d-16           [32, 64, 56, 56]             128\n",
            "           Conv2d-17           [32, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [32, 64, 56, 56]             128\n",
            "           Conv2d-19          [32, 256, 56, 56]          16,640\n",
            "      BatchNorm2d-20          [32, 256, 56, 56]             512\n",
            "             ReLU-21          [32, 256, 56, 56]               0\n",
            "   Residual_Block-22          [32, 256, 56, 56]               0\n",
            "           Conv2d-23           [32, 64, 56, 56]          16,448\n",
            "      BatchNorm2d-24           [32, 64, 56, 56]             128\n",
            "           Conv2d-25           [32, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-26           [32, 64, 56, 56]             128\n",
            "           Conv2d-27          [32, 256, 56, 56]          16,640\n",
            "      BatchNorm2d-28          [32, 256, 56, 56]             512\n",
            "             ReLU-29          [32, 256, 56, 56]               0\n",
            "   Residual_Block-30          [32, 256, 56, 56]               0\n",
            "           Conv2d-31          [32, 128, 56, 56]          32,896\n",
            "      BatchNorm2d-32          [32, 128, 56, 56]             256\n",
            "           Conv2d-33          [32, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-34          [32, 128, 28, 28]             256\n",
            "           Conv2d-35          [32, 512, 28, 28]          66,048\n",
            "      BatchNorm2d-36          [32, 512, 28, 28]           1,024\n",
            "           Conv2d-37          [32, 512, 28, 28]         131,584\n",
            "      BatchNorm2d-38          [32, 512, 28, 28]           1,024\n",
            "             ReLU-39          [32, 512, 28, 28]               0\n",
            "   Residual_Block-40          [32, 512, 28, 28]               0\n",
            "           Conv2d-41          [32, 128, 28, 28]          65,664\n",
            "      BatchNorm2d-42          [32, 128, 28, 28]             256\n",
            "           Conv2d-43          [32, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-44          [32, 128, 28, 28]             256\n",
            "           Conv2d-45          [32, 512, 28, 28]          66,048\n",
            "      BatchNorm2d-46          [32, 512, 28, 28]           1,024\n",
            "             ReLU-47          [32, 512, 28, 28]               0\n",
            "   Residual_Block-48          [32, 512, 28, 28]               0\n",
            "           Conv2d-49          [32, 128, 28, 28]          65,664\n",
            "      BatchNorm2d-50          [32, 128, 28, 28]             256\n",
            "           Conv2d-51          [32, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-52          [32, 128, 28, 28]             256\n",
            "           Conv2d-53          [32, 512, 28, 28]          66,048\n",
            "      BatchNorm2d-54          [32, 512, 28, 28]           1,024\n",
            "             ReLU-55          [32, 512, 28, 28]               0\n",
            "   Residual_Block-56          [32, 512, 28, 28]               0\n",
            "           Conv2d-57          [32, 128, 28, 28]          65,664\n",
            "      BatchNorm2d-58          [32, 128, 28, 28]             256\n",
            "           Conv2d-59          [32, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-60          [32, 128, 28, 28]             256\n",
            "           Conv2d-61          [32, 512, 28, 28]          66,048\n",
            "      BatchNorm2d-62          [32, 512, 28, 28]           1,024\n",
            "             ReLU-63          [32, 512, 28, 28]               0\n",
            "   Residual_Block-64          [32, 512, 28, 28]               0\n",
            "           Conv2d-65          [32, 256, 28, 28]         131,328\n",
            "      BatchNorm2d-66          [32, 256, 28, 28]             512\n",
            "           Conv2d-67          [32, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-68          [32, 256, 14, 14]             512\n",
            "           Conv2d-69         [32, 1024, 14, 14]         263,168\n",
            "      BatchNorm2d-70         [32, 1024, 14, 14]           2,048\n",
            "           Conv2d-71         [32, 1024, 14, 14]         525,312\n",
            "      BatchNorm2d-72         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-73         [32, 1024, 14, 14]               0\n",
            "   Residual_Block-74         [32, 1024, 14, 14]               0\n",
            "           Conv2d-75          [32, 256, 14, 14]         262,400\n",
            "      BatchNorm2d-76          [32, 256, 14, 14]             512\n",
            "           Conv2d-77          [32, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-78          [32, 256, 14, 14]             512\n",
            "           Conv2d-79         [32, 1024, 14, 14]         263,168\n",
            "      BatchNorm2d-80         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-81         [32, 1024, 14, 14]               0\n",
            "   Residual_Block-82         [32, 1024, 14, 14]               0\n",
            "           Conv2d-83          [32, 256, 14, 14]         262,400\n",
            "      BatchNorm2d-84          [32, 256, 14, 14]             512\n",
            "           Conv2d-85          [32, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-86          [32, 256, 14, 14]             512\n",
            "           Conv2d-87         [32, 1024, 14, 14]         263,168\n",
            "      BatchNorm2d-88         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [32, 1024, 14, 14]               0\n",
            "   Residual_Block-90         [32, 1024, 14, 14]               0\n",
            "           Conv2d-91          [32, 256, 14, 14]         262,400\n",
            "      BatchNorm2d-92          [32, 256, 14, 14]             512\n",
            "           Conv2d-93          [32, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-94          [32, 256, 14, 14]             512\n",
            "           Conv2d-95         [32, 1024, 14, 14]         263,168\n",
            "      BatchNorm2d-96         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-97         [32, 1024, 14, 14]               0\n",
            "   Residual_Block-98         [32, 1024, 14, 14]               0\n",
            "           Conv2d-99          [32, 256, 14, 14]         262,400\n",
            "     BatchNorm2d-100          [32, 256, 14, 14]             512\n",
            "          Conv2d-101          [32, 256, 14, 14]         590,080\n",
            "     BatchNorm2d-102          [32, 256, 14, 14]             512\n",
            "          Conv2d-103         [32, 1024, 14, 14]         263,168\n",
            "     BatchNorm2d-104         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-105         [32, 1024, 14, 14]               0\n",
            "  Residual_Block-106         [32, 1024, 14, 14]               0\n",
            "          Conv2d-107          [32, 256, 14, 14]         262,400\n",
            "     BatchNorm2d-108          [32, 256, 14, 14]             512\n",
            "          Conv2d-109          [32, 256, 14, 14]         590,080\n",
            "     BatchNorm2d-110          [32, 256, 14, 14]             512\n",
            "          Conv2d-111         [32, 1024, 14, 14]         263,168\n",
            "     BatchNorm2d-112         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-113         [32, 1024, 14, 14]               0\n",
            "  Residual_Block-114         [32, 1024, 14, 14]               0\n",
            "          Conv2d-115          [32, 512, 14, 14]         524,800\n",
            "     BatchNorm2d-116          [32, 512, 14, 14]           1,024\n",
            "          Conv2d-117            [32, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-118            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-119           [32, 2048, 7, 7]       1,050,624\n",
            "     BatchNorm2d-120           [32, 2048, 7, 7]           4,096\n",
            "          Conv2d-121           [32, 2048, 7, 7]       2,099,200\n",
            "     BatchNorm2d-122           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-123           [32, 2048, 7, 7]               0\n",
            "  Residual_Block-124           [32, 2048, 7, 7]               0\n",
            "          Conv2d-125            [32, 512, 7, 7]       1,049,088\n",
            "     BatchNorm2d-126            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-127            [32, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-128            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-129           [32, 2048, 7, 7]       1,050,624\n",
            "     BatchNorm2d-130           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-131           [32, 2048, 7, 7]               0\n",
            "  Residual_Block-132           [32, 2048, 7, 7]               0\n",
            "          Conv2d-133            [32, 512, 7, 7]       1,049,088\n",
            "     BatchNorm2d-134            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-135            [32, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-136            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-137           [32, 2048, 7, 7]       1,050,624\n",
            "     BatchNorm2d-138           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-139           [32, 2048, 7, 7]               0\n",
            "  Residual_Block-140           [32, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-141           [32, 2048, 1, 1]               0\n",
            "          Linear-142                    [32, 4]           8,196\n",
            "================================================================\n",
            "Total params: 23,542,788\n",
            "Trainable params: 23,542,788\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 18.38\n",
            "Forward/backward pass size (MB): 8367.25\n",
            "Params size (MB): 89.81\n",
            "Estimated Total Size (MB): 8475.43\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64iVEIrkuO_l"
      },
      "source": [
        "Loss= nn.CrossEntropyLoss()\r\n",
        "optimizer= optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8_tWGcWu9v2"
      },
      "source": [
        "def check_accuracy(scores, targets):\r\n",
        "\r\n",
        "  num_correct=0\r\n",
        "  num_samples=0\r\n",
        "  _, predictions= scores.max(1)\r\n",
        "  num_correct+= (predictions== targets).sum()\r\n",
        "  num_samples= predictions.size(0)\r\n",
        "\r\n",
        "  return num_correct/num_samples"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F81oPGN8duv-"
      },
      "source": [
        "def save_checkpoint(model, optimizer, file_name):\r\n",
        "\r\n",
        "  checkpoint= {'state_dict': model.state_dict(),\r\n",
        "             'optimizer_dict': optimizer.state_dict()}\r\n",
        "  torch.save(checkpoint,file_name)\r\n",
        "\r\n",
        "def load_checkpoint(model, optimizer, file_name):\r\n",
        "  check_pt= torch.load(file_name)\r\n",
        "  model.load_state_dict(check_pt['state_dict'])\r\n",
        "  optimizer.load_state_dict(check_pt['optimizer_dict'])\r\n",
        "\r\n",
        "  return model, optimizer"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPowtOToAtic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77257749-fe4c-4c5d-c6e9-098136272389"
      },
      "source": [
        "train_per_epoch= len(train_loader)\r\n",
        "val_per_epoch= len(val_loader)\r\n",
        "min_loss= math.inf\r\n",
        "min_loss\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "  train_losses=[]\r\n",
        "### TRAINING\r\n",
        "\r\n",
        "  kbar_train= pkbar.Kbar(target= train_per_epoch, epoch=epoch, num_epochs=num_epochs)\r\n",
        "\r\n",
        "  train_loop= enumerate(train_loader)\r\n",
        "  val_loop= enumerate(val_loader)\r\n",
        "  for batch_idx, (data,targets) in train_loop:\r\n",
        "\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    data= data.to(device=device)\r\n",
        "    targets= targets.to(device=device)\r\n",
        "\r\n",
        "    # FORWARD PROP\r\n",
        "\r\n",
        "    scores= model(data)\r\n",
        "    train_loss= Loss(scores, targets)\r\n",
        "    train_losses.append(train_loss.item())\r\n",
        "\r\n",
        "    # BACKWARD PROP\r\n",
        "    optimizer.zero_grad()\r\n",
        "    train_loss.backward()\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    train_acc= check_accuracy(scores,targets)\r\n",
        "\r\n",
        "    kbar_train.update(batch_idx, values=[(\"loss\", train_loss.item()), (\"accuracy\", train_acc.item())])\r\n",
        "\r\n",
        "  kbar_train.update(train_per_epoch, values=None)\r\n",
        "### VALIDATION\r\n",
        "\r\n",
        "  kbar_val= pkbar.Kbar(target= val_per_epoch, epoch=epoch, num_epochs=num_epochs)\r\n",
        "\r\n",
        "\r\n",
        "  for batch_idx, (data, targets) in val_loop:\r\n",
        "\r\n",
        "    val_losses=[]\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    \r\n",
        "    data= data.to(device=device)\r\n",
        "    targets= targets.to(device=device)\r\n",
        "    scores= model(data)\r\n",
        "    val_loss= Loss(scores, targets)\r\n",
        "    val_losses.append(val_loss.item())\r\n",
        "    val_acc= check_accuracy(scores,targets)\r\n",
        "\r\n",
        "    kbar_val.update(batch_idx, values=[(\"val_loss\", val_loss.item()), (\"val_accuracy\", val_acc.item())])\r\n",
        "\r\n",
        "  if np.mean(val_losses)<min_loss:\r\n",
        "    min_loss= val_loss.item()\r\n",
        "    print('\\nImproved validation loss: {:.4f}'.format(val_loss.item()))\r\n",
        "    print('Saving the model to {}\\n'.format(check_pt_file))\r\n",
        "    save_checkpoint(model, optimizer, check_pt_file)\r\n",
        "    \r\n",
        "  kbar_val.update(val_per_epoch, values=None)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 1.3523 - accuracy: 0.3134\n",
            "Epoch: 1/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 1.3451 - val_accuracy: 0.2708\n",
            "Improved validation loss: 1.3532\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 377ms/step - val_loss: 1.3451 - val_accuracy: 0.2708\n",
            "Epoch: 2/100\n",
            "83/83 [==============================] - 47s 569ms/step - loss: 1.1869 - accuracy: 0.4471\n",
            "Epoch: 2/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 1.0735 - val_accuracy: 0.4753\n",
            "Improved validation loss: 1.0533\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 376ms/step - val_loss: 1.0735 - val_accuracy: 0.4753\n",
            "Epoch: 3/100\n",
            "83/83 [==============================] - 47s 567ms/step - loss: 0.8430 - accuracy: 0.6287\n",
            "Epoch: 3/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.8559 - val_accuracy: 0.6810\n",
            "Improved validation loss: 0.7995\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 375ms/step - val_loss: 0.8559 - val_accuracy: 0.6810\n",
            "Epoch: 4/100\n",
            "83/83 [==============================] - 47s 567ms/step - loss: 0.6898 - accuracy: 0.6838\n",
            "Epoch: 4/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.5849 - val_accuracy: 0.8008\n",
            "Improved validation loss: 0.7743\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 375ms/step - val_loss: 0.5849 - val_accuracy: 0.8008\n",
            "Epoch: 5/100\n",
            "83/83 [==============================] - 47s 566ms/step - loss: 0.6319 - accuracy: 0.7233\n",
            "Epoch: 5/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.5922 - val_accuracy: 0.7357\n",
            "Improved validation loss: 0.4725\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 374ms/step - val_loss: 0.5922 - val_accuracy: 0.7357\n",
            "Epoch: 6/100\n",
            "83/83 [==============================] - 47s 567ms/step - loss: 0.5952 - accuracy: 0.7194\n",
            "Epoch: 6/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.5934 - val_accuracy: 0.7930\n",
            "Improved validation loss: 0.3055\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 381ms/step - val_loss: 0.5934 - val_accuracy: 0.7930\n",
            "Epoch: 7/100\n",
            "83/83 [==============================] - 47s 566ms/step - loss: 0.5662 - accuracy: 0.7381\n",
            "Epoch: 7/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.6084 - val_accuracy: 0.8346\n",
            "Epoch: 8/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.5342 - accuracy: 0.7438\n",
            "Epoch: 8/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.5069 - val_accuracy: 0.7552\n",
            "Epoch: 9/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.5118 - accuracy: 0.7688\n",
            "Epoch: 9/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.4748 - val_accuracy: 0.7708\n",
            "Epoch: 10/100\n",
            "83/83 [==============================] - 47s 563ms/step - loss: 0.5027 - accuracy: 0.7666\n",
            "Epoch: 10/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.4470 - val_accuracy: 0.7995\n",
            "Epoch: 11/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.4974 - accuracy: 0.7723\n",
            "Epoch: 11/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.4640 - val_accuracy: 0.8281\n",
            "Epoch: 12/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.4931 - accuracy: 0.7749\n",
            "Epoch: 12/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.4235 - val_accuracy: 0.8346\n",
            "Epoch: 13/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.4767 - accuracy: 0.7836\n",
            "Epoch: 13/100\n",
            "9/9 [==============================] - 2s 236ms/step - val_loss: 0.5036 - val_accuracy: 0.7721\n",
            "Epoch: 14/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.4813 - accuracy: 0.7844\n",
            "Epoch: 14/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.4048 - val_accuracy: 0.8672\n",
            "Epoch: 15/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.4406 - accuracy: 0.8052\n",
            "Epoch: 15/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.3653 - val_accuracy: 0.8841\n",
            "Improved validation loss: 0.1976\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 381ms/step - val_loss: 0.3653 - val_accuracy: 0.8841\n",
            "Epoch: 16/100\n",
            "83/83 [==============================] - 47s 566ms/step - loss: 0.4297 - accuracy: 0.8076\n",
            "Epoch: 16/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.4493 - val_accuracy: 0.7852\n",
            "Epoch: 17/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.4340 - accuracy: 0.8168\n",
            "Epoch: 17/100\n",
            "9/9 [==============================] - 2s 236ms/step - val_loss: 0.4535 - val_accuracy: 0.8724\n",
            "Epoch: 18/100\n",
            "83/83 [==============================] - 47s 560ms/step - loss: 0.4169 - accuracy: 0.8221\n",
            "Epoch: 18/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.3331 - val_accuracy: 0.8919\n",
            "Epoch: 19/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.4153 - accuracy: 0.8069\n",
            "Epoch: 19/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.3640 - val_accuracy: 0.8763\n",
            "Epoch: 20/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.3965 - accuracy: 0.8251\n",
            "Epoch: 20/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.4959 - val_accuracy: 0.8581\n",
            "Epoch: 21/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.3852 - accuracy: 0.8302\n",
            "Epoch: 21/100\n",
            "9/9 [==============================] - 2s 235ms/step - val_loss: 0.3820 - val_accuracy: 0.8828\n",
            "Epoch: 22/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.3844 - accuracy: 0.8309\n",
            "Epoch: 22/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.3827 - val_accuracy: 0.7943\n",
            "Epoch: 23/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.3756 - accuracy: 0.8377\n",
            "Epoch: 23/100\n",
            "9/9 [==============================] - 2s 235ms/step - val_loss: 0.4654 - val_accuracy: 0.8229\n",
            "Epoch: 24/100\n",
            "83/83 [==============================] - 46s 559ms/step - loss: 0.3562 - accuracy: 0.8395\n",
            "Epoch: 24/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.4309 - val_accuracy: 0.8516\n",
            "Epoch: 25/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.3503 - accuracy: 0.8447\n",
            "Epoch: 25/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.4291 - val_accuracy: 0.8581\n",
            "Epoch: 26/100\n",
            "83/83 [==============================] - 47s 560ms/step - loss: 0.3603 - accuracy: 0.8454\n",
            "Epoch: 26/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.2876 - val_accuracy: 0.8906\n",
            "Epoch: 27/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.3419 - accuracy: 0.8448\n",
            "Epoch: 27/100\n",
            "9/9 [==============================] - 2s 242ms/step - val_loss: 0.3075 - val_accuracy: 0.8711\n",
            "Epoch: 28/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.3515 - accuracy: 0.8415\n",
            "Epoch: 28/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.3265 - val_accuracy: 0.8451\n",
            "Epoch: 29/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.3300 - accuracy: 0.8558\n",
            "Epoch: 29/100\n",
            "9/9 [==============================] - 2s 235ms/step - val_loss: 0.3527 - val_accuracy: 0.8659\n",
            "Epoch: 30/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.3047 - accuracy: 0.8705\n",
            "Epoch: 30/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.3186 - val_accuracy: 0.8750\n",
            "Epoch: 31/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.3108 - accuracy: 0.8613\n",
            "Epoch: 31/100\n",
            "9/9 [==============================] - 2s 234ms/step - val_loss: 0.3302 - val_accuracy: 0.8594\n",
            "Epoch: 32/100\n",
            "83/83 [==============================] - 46s 559ms/step - loss: 0.3176 - accuracy: 0.8607\n",
            "Epoch: 32/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.3601 - val_accuracy: 0.8503\n",
            "Epoch: 33/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.3127 - accuracy: 0.8599\n",
            "Epoch: 33/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.2485 - val_accuracy: 0.8841\n",
            "Improved validation loss: 0.1832\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 366ms/step - val_loss: 0.2485 - val_accuracy: 0.8841\n",
            "Epoch: 34/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.3049 - accuracy: 0.8670\n",
            "Epoch: 34/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.2948 - val_accuracy: 0.9115\n",
            "Improved validation loss: 0.1584\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 366ms/step - val_loss: 0.2948 - val_accuracy: 0.9115\n",
            "Epoch: 35/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.3060 - accuracy: 0.8650\n",
            "Epoch: 35/100\n",
            "9/9 [==============================] - 2s 241ms/step - val_loss: 0.3647 - val_accuracy: 0.8477\n",
            "Epoch: 36/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2803 - accuracy: 0.8776\n",
            "Epoch: 36/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.2852 - val_accuracy: 0.8919\n",
            "Epoch: 37/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.3002 - accuracy: 0.8633\n",
            "Epoch: 37/100\n",
            "9/9 [==============================] - 2s 241ms/step - val_loss: 0.2101 - val_accuracy: 0.8789\n",
            "Epoch: 38/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.3122 - accuracy: 0.8600\n",
            "Epoch: 38/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.2769 - val_accuracy: 0.8919\n",
            "Improved validation loss: 0.1355\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 369ms/step - val_loss: 0.2769 - val_accuracy: 0.8919\n",
            "Epoch: 39/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.2967 - accuracy: 0.8669\n",
            "Epoch: 39/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.3692 - val_accuracy: 0.8776\n",
            "Epoch: 40/100\n",
            "83/83 [==============================] - 47s 560ms/step - loss: 0.2880 - accuracy: 0.8778\n",
            "Epoch: 40/100\n",
            "9/9 [==============================] - 2s 241ms/step - val_loss: 0.2916 - val_accuracy: 0.8958\n",
            "Epoch: 41/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.2750 - accuracy: 0.8749\n",
            "Epoch: 41/100\n",
            "9/9 [==============================] - 2s 236ms/step - val_loss: 0.2620 - val_accuracy: 0.8854\n",
            "Epoch: 42/100\n",
            "83/83 [==============================] - 47s 563ms/step - loss: 0.2704 - accuracy: 0.8811\n",
            "Epoch: 42/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.2766 - val_accuracy: 0.8919\n",
            "Epoch: 43/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2548 - accuracy: 0.8860\n",
            "Epoch: 43/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.3664 - val_accuracy: 0.8438\n",
            "Epoch: 44/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.2636 - accuracy: 0.8807\n",
            "Epoch: 44/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.2856 - val_accuracy: 0.8659\n",
            "Improved validation loss: 0.1320\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 372ms/step - val_loss: 0.2856 - val_accuracy: 0.8659\n",
            "Epoch: 45/100\n",
            "83/83 [==============================] - 47s 563ms/step - loss: 0.2743 - accuracy: 0.8696\n",
            "Epoch: 45/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.3759 - val_accuracy: 0.8607\n",
            "Epoch: 46/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.2460 - accuracy: 0.8958\n",
            "Epoch: 46/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.2584 - val_accuracy: 0.8945\n",
            "Epoch: 47/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.2558 - accuracy: 0.8867\n",
            "Epoch: 47/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.2336 - val_accuracy: 0.9049\n",
            "Improved validation loss: 0.1003\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 373ms/step - val_loss: 0.2336 - val_accuracy: 0.9049\n",
            "Epoch: 48/100\n",
            "83/83 [==============================] - 47s 566ms/step - loss: 0.2366 - accuracy: 0.8932\n",
            "Epoch: 48/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.2308 - val_accuracy: 0.8958\n",
            "Epoch: 49/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2481 - accuracy: 0.8932\n",
            "Epoch: 49/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.2838 - val_accuracy: 0.8906\n",
            "Epoch: 50/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.2554 - accuracy: 0.8903\n",
            "Epoch: 50/100\n",
            "9/9 [==============================] - 2s 240ms/step - val_loss: 0.2383 - val_accuracy: 0.8932\n",
            "Epoch: 51/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2311 - accuracy: 0.8938\n",
            "Epoch: 51/100\n",
            "9/9 [==============================] - 2s 240ms/step - val_loss: 0.2111 - val_accuracy: 0.8984\n",
            "Epoch: 52/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2435 - accuracy: 0.8949\n",
            "Epoch: 52/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.3099 - val_accuracy: 0.8854\n",
            "Epoch: 53/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.2448 - accuracy: 0.8892\n",
            "Epoch: 53/100\n",
            "9/9 [==============================] - 2s 235ms/step - val_loss: 0.2851 - val_accuracy: 0.8828\n",
            "Epoch: 54/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2395 - accuracy: 0.8916\n",
            "Epoch: 54/100\n",
            "9/9 [==============================] - 2s 243ms/step - val_loss: 0.2095 - val_accuracy: 0.8971\n",
            "Epoch: 55/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2279 - accuracy: 0.8972\n",
            "Epoch: 55/100\n",
            "9/9 [==============================] - 2s 235ms/step - val_loss: 0.3597 - val_accuracy: 0.8646\n",
            "Epoch: 56/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2353 - accuracy: 0.9021\n",
            "Epoch: 56/100\n",
            "9/9 [==============================] - 2s 235ms/step - val_loss: 0.2363 - val_accuracy: 0.8672\n",
            "Epoch: 57/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.2384 - accuracy: 0.8970\n",
            "Epoch: 57/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.2737 - val_accuracy: 0.8776\n",
            "Epoch: 58/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2280 - accuracy: 0.9000\n",
            "Epoch: 58/100\n",
            "9/9 [==============================] - 2s 236ms/step - val_loss: 0.2245 - val_accuracy: 0.8958\n",
            "Epoch: 59/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2200 - accuracy: 0.8928\n",
            "Epoch: 59/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.2532 - val_accuracy: 0.8802\n",
            "Epoch: 60/100\n",
            "83/83 [==============================] - 46s 559ms/step - loss: 0.2181 - accuracy: 0.8971\n",
            "Epoch: 60/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.4343 - val_accuracy: 0.8451\n",
            "Epoch: 61/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.2290 - accuracy: 0.9006\n",
            "Epoch: 61/100\n",
            "9/9 [==============================] - 2s 238ms/step - val_loss: 0.1843 - val_accuracy: 0.9154\n",
            "Epoch: 62/100\n",
            "83/83 [==============================] - 47s 560ms/step - loss: 0.2317 - accuracy: 0.9041\n",
            "Epoch: 62/100\n",
            "9/9 [==============================] - 2s 240ms/step - val_loss: 0.1874 - val_accuracy: 0.9193\n",
            "Epoch: 63/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2200 - accuracy: 0.9002\n",
            "Epoch: 63/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.3076 - val_accuracy: 0.8594\n",
            "Epoch: 64/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2110 - accuracy: 0.9092\n",
            "Epoch: 64/100\n",
            "9/9 [==============================] - 2s 235ms/step - val_loss: 0.2304 - val_accuracy: 0.8906\n",
            "Epoch: 65/100\n",
            "83/83 [==============================] - 46s 560ms/step - loss: 0.1950 - accuracy: 0.9126\n",
            "Epoch: 65/100\n",
            "9/9 [==============================] - 2s 243ms/step - val_loss: 0.2189 - val_accuracy: 0.8945\n",
            "Epoch: 66/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.2071 - accuracy: 0.9050\n",
            "Epoch: 66/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.2665 - val_accuracy: 0.8776\n",
            "Epoch: 67/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.2269 - accuracy: 0.9019\n",
            "Epoch: 67/100\n",
            "9/9 [==============================] - 2s 241ms/step - val_loss: 0.2424 - val_accuracy: 0.8932\n",
            "Epoch: 68/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.1970 - accuracy: 0.9124\n",
            "Epoch: 68/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.1429 - val_accuracy: 0.9245\n",
            "Improved validation loss: 0.0488\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_6.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 370ms/step - val_loss: 0.1429 - val_accuracy: 0.9245\n",
            "Epoch: 69/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.2181 - accuracy: 0.9046\n",
            "Epoch: 69/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.2646 - val_accuracy: 0.8932\n",
            "Epoch: 70/100\n",
            "83/83 [==============================] - 46s 559ms/step - loss: 0.2009 - accuracy: 0.9091\n",
            "Epoch: 70/100\n",
            "9/9 [==============================] - 2s 242ms/step - val_loss: 0.2464 - val_accuracy: 0.8971\n",
            "Epoch: 71/100\n",
            "83/83 [==============================] - 46s 559ms/step - loss: 0.1933 - accuracy: 0.9151\n",
            "Epoch: 71/100\n",
            "9/9 [==============================] - 2s 236ms/step - val_loss: 0.2040 - val_accuracy: 0.9089\n",
            "Epoch: 72/100\n",
            "83/83 [==============================] - 47s 560ms/step - loss: 0.2064 - accuracy: 0.9098\n",
            "Epoch: 72/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.1800 - val_accuracy: 0.9284\n",
            "Epoch: 73/100\n",
            "83/83 [==============================] - 47s 560ms/step - loss: 0.2176 - accuracy: 0.9043\n",
            "Epoch: 73/100\n",
            "9/9 [==============================] - 2s 241ms/step - val_loss: 0.1548 - val_accuracy: 0.9258\n",
            "Epoch: 74/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.2044 - accuracy: 0.9095\n",
            "Epoch: 74/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.1807 - val_accuracy: 0.9115\n",
            "Epoch: 75/100\n",
            "83/83 [==============================] - 47s 560ms/step - loss: 0.1811 - accuracy: 0.9233\n",
            "Epoch: 75/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.2255 - val_accuracy: 0.8958\n",
            "Epoch: 76/100\n",
            "83/83 [==============================] - 47s 560ms/step - loss: 0.2082 - accuracy: 0.9117\n",
            "Epoch: 76/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.1754 - val_accuracy: 0.8958\n",
            "Epoch: 77/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.2041 - accuracy: 0.9116\n",
            "Epoch: 77/100\n",
            "9/9 [==============================] - 2s 241ms/step - val_loss: 0.2073 - val_accuracy: 0.8815\n",
            "Epoch: 78/100\n",
            "83/83 [==============================] - 47s 563ms/step - loss: 0.1889 - accuracy: 0.9179\n",
            "Epoch: 78/100\n",
            "9/9 [==============================] - 2s 240ms/step - val_loss: 0.1511 - val_accuracy: 0.9284\n",
            "Epoch: 79/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.1980 - accuracy: 0.9140\n",
            "Epoch: 79/100\n",
            "9/9 [==============================] - 2s 240ms/step - val_loss: 0.1304 - val_accuracy: 0.9414\n",
            "Epoch: 80/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.1954 - accuracy: 0.9090\n",
            "Epoch: 80/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.2260 - val_accuracy: 0.8997\n",
            "Epoch: 81/100\n",
            "83/83 [==============================] - 47s 561ms/step - loss: 0.1798 - accuracy: 0.9183\n",
            "Epoch: 81/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.2873 - val_accuracy: 0.8789\n",
            "Epoch: 82/100\n",
            "83/83 [==============================] - 47s 565ms/step - loss: 0.1953 - accuracy: 0.9185\n",
            "Epoch: 82/100\n",
            "9/9 [==============================] - 2s 244ms/step - val_loss: 0.2679 - val_accuracy: 0.8828\n",
            "Epoch: 83/100\n",
            "83/83 [==============================] - 47s 566ms/step - loss: 0.1965 - accuracy: 0.9091\n",
            "Epoch: 83/100\n",
            "9/9 [==============================] - 2s 242ms/step - val_loss: 0.1963 - val_accuracy: 0.9023\n",
            "Epoch: 84/100\n",
            "83/83 [==============================] - 47s 568ms/step - loss: 0.1893 - accuracy: 0.9207\n",
            "Epoch: 84/100\n",
            "9/9 [==============================] - 2s 242ms/step - val_loss: 0.2626 - val_accuracy: 0.8906\n",
            "Epoch: 85/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.1870 - accuracy: 0.9155\n",
            "Epoch: 85/100\n",
            "9/9 [==============================] - 2s 237ms/step - val_loss: 0.1951 - val_accuracy: 0.9193\n",
            "Epoch: 86/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.1772 - accuracy: 0.9238\n",
            "Epoch: 86/100\n",
            "9/9 [==============================] - 2s 241ms/step - val_loss: 0.2375 - val_accuracy: 0.9115\n",
            "Epoch: 87/100\n",
            "83/83 [==============================] - 47s 565ms/step - loss: 0.2016 - accuracy: 0.9158\n",
            "Epoch: 87/100\n",
            "9/9 [==============================] - 2s 242ms/step - val_loss: 0.2366 - val_accuracy: 0.8802\n",
            "Epoch: 88/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.1841 - accuracy: 0.9171\n",
            "Epoch: 88/100\n",
            "9/9 [==============================] - 2s 240ms/step - val_loss: 0.2941 - val_accuracy: 0.8828\n",
            "Epoch: 89/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.1821 - accuracy: 0.9190\n",
            "Epoch: 89/100\n",
            "9/9 [==============================] - 2s 243ms/step - val_loss: 0.1966 - val_accuracy: 0.9010\n",
            "Epoch: 90/100\n",
            "83/83 [==============================] - 47s 562ms/step - loss: 0.1748 - accuracy: 0.9237\n",
            "Epoch: 90/100\n",
            "9/9 [==============================] - 2s 244ms/step - val_loss: 0.2356 - val_accuracy: 0.9115\n",
            "Epoch: 91/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.1617 - accuracy: 0.9280\n",
            "Epoch: 91/100\n",
            "9/9 [==============================] - 2s 240ms/step - val_loss: 0.1376 - val_accuracy: 0.9154\n",
            "Epoch: 92/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.1704 - accuracy: 0.9239\n",
            "Epoch: 92/100\n",
            "9/9 [==============================] - 2s 239ms/step - val_loss: 0.1993 - val_accuracy: 0.9128\n",
            "Epoch: 93/100\n",
            "83/83 [==============================] - 47s 566ms/step - loss: 0.1852 - accuracy: 0.9196\n",
            "Epoch: 93/100\n",
            "9/9 [==============================] - 2s 241ms/step - val_loss: 0.1961 - val_accuracy: 0.8984\n",
            "Epoch: 94/100\n",
            "83/83 [==============================] - 47s 564ms/step - loss: 0.1824 - accuracy: 0.9218\n",
            "Epoch: 94/100\n",
            "9/9 [==============================] - 2s 242ms/step - val_loss: 0.1754 - val_accuracy: 0.9141\n",
            "Epoch: 95/100\n",
            "83/83 [==============================] - 47s 563ms/step - loss: 0.1599 - accuracy: 0.9281\n",
            "Epoch: 95/100\n",
            "9/9 [==============================] - 2s 240ms/step - val_loss: 0.1787 - val_accuracy: 0.9193\n",
            "Epoch: 96/100\n",
            "83/83 [==============================] - 47s 566ms/step - loss: 0.1745 - accuracy: 0.9202\n",
            "Epoch: 96/100\n",
            "9/9 [==============================] - 2s 247ms/step - val_loss: 0.2107 - val_accuracy: 0.9128\n",
            "Epoch: 97/100\n",
            "83/83 [==============================] - 47s 569ms/step - loss: 0.1719 - accuracy: 0.9324\n",
            "Epoch: 97/100\n",
            "9/9 [==============================] - 2s 243ms/step - val_loss: 0.2184 - val_accuracy: 0.8789\n",
            "Epoch: 98/100\n",
            "83/83 [==============================] - 47s 566ms/step - loss: 0.1654 - accuracy: 0.9292\n",
            "Epoch: 98/100\n",
            "9/9 [==============================] - 2s 241ms/step - val_loss: 0.1256 - val_accuracy: 0.9193\n",
            "Epoch: 99/100\n",
            "83/83 [==============================] - 47s 568ms/step - loss: 0.1595 - accuracy: 0.9274\n",
            "Epoch: 99/100\n",
            "9/9 [==============================] - 2s 242ms/step - val_loss: 0.1539 - val_accuracy: 0.9232\n",
            "Epoch: 100/100\n",
            "83/83 [==============================] - 47s 567ms/step - loss: 0.1631 - accuracy: 0.9389\n",
            "Epoch: 100/100\n",
            "9/9 [==============================] - 2s 244ms/step - val_loss: 0.2701 - val_accuracy: 0.8893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_YKfqi6JXq8"
      },
      "source": [
        "def CONFUSION_MATRIX(y_true, y_pred, class_labels, order=False):\r\n",
        "  \r\n",
        "  num_classes= len(class_labels)\r\n",
        "  num_examples= len(y_true)\r\n",
        "\r\n",
        "  if order is False:\r\n",
        "    new_labels= np.arange(num_classes)\r\n",
        "    \r\n",
        "    for i in range(num_examples):\r\n",
        "      y_true[i].item= np.where(class_labels==y_true[i])[0]\r\n",
        "      y_pred[i].item= np.where(class_labels==y_pred[i])[0]\r\n",
        "\r\n",
        "  mat= np.zeros((num_classes,num_classes), dtype=np.int)\r\n",
        "  \r\n",
        "  for i in range(num_examples):\r\n",
        "    true= np.uint8(y_true[i].item())\r\n",
        "    pred= np.uint8(y_pred[i].item())\r\n",
        "\r\n",
        "    mat[true,pred]+=1\r\n",
        "\r\n",
        "  return mat\r\n",
        "\r\n",
        "\r\n",
        "def acc_precision_recall_f1(confusion_matrix):\r\n",
        "\r\n",
        "  num_classes= confusion_matrix.shape[0]\r\n",
        "  precision=      np.zeros((num_classes,1), np.float64)\r\n",
        "  recall=         np.zeros((num_classes,1), np.float64)\r\n",
        "  true_positives= np.zeros((num_classes,1), np.float64)\r\n",
        "  true_negatives= np.zeros((num_classes,1), np.float64)\r\n",
        "  accuracy=       np.zeros((num_classes,1), np.float64)\r\n",
        "  f1=             np.zeros((num_classes,1), np.float64)\r\n",
        "\r\n",
        "  for i in range(num_classes):\r\n",
        "    \r\n",
        "    true_positives[i]= confusion_matrix[i,i]\r\n",
        "    precision[i]= confusion_matrix[i,i]/np.sum(confusion_matrix[i])\r\n",
        "    recall[i]= confusion_matrix[i,i]/np.sum(confusion_matrix[:,i])\r\n",
        "    f1[i]= 2*precision[i]*recall[i]/(precision[i]+recall[i])\r\n",
        "  \r\n",
        "\r\n",
        "  for i in range(num_classes):\r\n",
        "    true_negatives[i]=0\r\n",
        "    for j in range(num_classes):\r\n",
        "      for k in range(num_classes):\r\n",
        "        if (j!=i) and (k!=i):\r\n",
        "          true_negatives[i]+=confusion_matrix[j,k]\r\n",
        "\r\n",
        "  accuracy= (true_positives+true_negatives)/np.sum(confusion_matrix)\r\n",
        "  return accuracy, precision, recall, f1\r\n",
        "\r\n",
        "\r\n",
        "def Final_Metrics(loader, model, class_labels):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    size= len(class_labels)\r\n",
        "    c_mat= np.zeros((size,size), dtype= np.int)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for x, y in loader:\r\n",
        "            x = x.to(device=device)\r\n",
        "            y = y.to(device=device)\r\n",
        "\r\n",
        "            scores= model(x)\r\n",
        "            _, preds = scores.max(1)\r\n",
        "\r\n",
        "            c_mat+= CONFUSION_MATRIX(y, preds, class_labels, order= True)\r\n",
        "    \r\n",
        "    accuracy, precision, recall, f1= acc_precision_recall_f1(c_mat)\r\n",
        "\r\n",
        "    return c_mat, accuracy, precision, recall, f1"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8cRuzw9wVaK"
      },
      "source": [
        "resnet_50, _= load_checkpoint(model, optimizer, check_pt_file)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqdAZbNtudpl"
      },
      "source": [
        "confusion_matrix, accuracy, precision, recall, f1= Final_Metrics(test_loader, resnet_50, class_labels)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcVhQQ8Hu5D6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef7ae23c-7daf-447a-d7fa-b91179c4f741"
      },
      "source": [
        "print(confusion_matrix)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[70  0  0  0]\n",
            " [ 0 75  5  0]\n",
            " [ 0  8 72  0]\n",
            " [ 0  0  5 45]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t93P6U8_vqEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "053365bf-f564-4889-f51a-96123ef373db"
      },
      "source": [
        "print(precision)\r\n",
        "print(np.mean(precision))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.    ]\n",
            " [0.9375]\n",
            " [0.9   ]\n",
            " [0.9   ]]\n",
            "0.934375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31oaOfIKvsnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aee786f-d331-47f7-c262-fa501aa5f8e0"
      },
      "source": [
        "print(recall.T)\r\n",
        "print(np.mean(recall))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.90361446 0.87804878 1.        ]]\n",
            "0.9454158095797826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5f_VjUyvvnR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07dde828-21a9-4dfb-941d-4a780ef93015"
      },
      "source": [
        " print(f1.T)\r\n",
        " print(np.mean(f1))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.9202454  0.88888889 0.94736842]]\n",
            "0.9391256771786316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMPXNPnjv02l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3257b8d8-3c71-4818-8c82-3ff309a43fc1"
      },
      "source": [
        "print(accuracy.T)\r\n",
        "print(np.mean(accuracy))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.95357143 0.93571429 0.98214286]]\n",
            "0.9678571428571429\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}