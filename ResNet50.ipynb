{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jyvQUouwF2Tn22a2ZghmXYx5NyaDkHuW",
      "authorship_tag": "ABX9TyMadySUvsjxt5GWMwBphlfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashrikant39/Histopatgology-Image-Classification/blob/main/ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOnzBnai_RVp"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision\r\n",
        "from torchsummary import summary\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import math\r\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm62yiRGGzFS",
        "outputId": "08c3d05f-4663-4bf3-89e2-c25afc2cd2de"
      },
      "source": [
        "!pip install pkbar\r\n",
        "import pkbar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pkbar\n",
            "  Downloading https://files.pythonhosted.org/packages/95/8f/28e0a21b27f836a8903315050db17dd68e55bf477b6fde52d1c68da3c8a6/pkbar-0.5-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pkbar) (1.19.5)\n",
            "Installing collected packages: pkbar\n",
            "Successfully installed pkbar-0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVoBgr3YAP9v"
      },
      "source": [
        "batch_size= 32\r\n",
        "device = 'cuda'\r\n",
        "num_classes= 4\r\n",
        "input_shape=(3,224,224)\r\n",
        "layers= [3,4,6,3]\r\n",
        "learning_rate=1e-4\r\n",
        "num_epochs= 100"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao3vjZ8nfaRy",
        "outputId": "2c1aa993-de88-47be-9a30-7766482160d3"
      },
      "source": [
        "main_path= 'drive/My Drive/Hist_folder/KMC Dataset'\r\n",
        "train_dir= os.path.join(main_path,'Training')\r\n",
        "test_dir= os.path.join(main_path,'Test')\r\n",
        "val_dir= os.path.join(main_path,'Validation')\r\n",
        "\r\n",
        "check_pt_file= os.path.join(main_path, 'ResNet50_Checkpoint_3.pth.tar')\r\n",
        "\r\n",
        "print(os.listdir(main_path))\r\n",
        "print(os.listdir(train_dir))\r\n",
        "print(os.listdir(test_dir))\r\n",
        "print(os.listdir(val_dir))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Training', 'Validation', 'Test', 'ResNet50_Checkpoint_1.pth.tar', 'AlexNet.ipynb', 'AlexNet_checkpoint.pth.tar', 'DenseNet.ipynb', 'ResNet50_Checkpoint_2.pth.tar', 'ResNet50_Checkpoint_3.pth.tar', 'ResNet50.ipynb']\n",
            "['grade1', 'grade3', 'grade2', 'grade0']\n",
            "['grade1', 'grade0', 'grade2', 'grade3']\n",
            "['grade2', 'grade1', 'grade0', 'grade3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSDTwhDqOG8m"
      },
      "source": [
        "my_transforms = transforms.Compose([ #Compose makes it possible to have many transforms\r\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3), # Change brightness of image\r\n",
        "    transforms.RandomRotation(degrees=45), # Perhaps a random rotation from -45 to 45 degrees\r\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # Flips the image horizontally with probability 0.5\r\n",
        "    transforms.RandomVerticalFlip(p=0.05), # Flips image vertically with probability 0.05\r\n",
        "    transforms.ToTensor() # Finally converts PIL image to tensor so we can train w. pytorch\r\n",
        "    ])\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x2vEw-Tf_vk"
      },
      "source": [
        "train_data= datasets.ImageFolder(train_dir, transform= my_transforms)\r\n",
        "test_data= datasets.ImageFolder(test_dir, transform= transforms.ToTensor())\r\n",
        "val_data= datasets.ImageFolder(val_dir, transform= transforms.ToTensor())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEDaY7p9gsEz"
      },
      "source": [
        "train_loader= DataLoader(train_data, batch_size=batch_size, shuffle=True)\r\n",
        "test_loader= DataLoader(test_data, batch_size=batch_size, shuffle=True)\r\n",
        "val_loader= DataLoader(val_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCHEpxdooz1E",
        "outputId": "2cc95a8d-5558-42d8-c1df-f0742494bfe8"
      },
      "source": [
        "class_dict=train_data.class_to_idx\r\n",
        "class_labels = class_dict.values()\r\n",
        "print(class_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_values([0, 1, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWJYfR16O-0l"
      },
      "source": [
        "### Plotting the images with classes\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIA-Bc-iKHT"
      },
      "source": [
        "# iterator= iter(train_loader)\r\n",
        "# it= next(iterator)\r\n",
        "# images, labels= it\r\n",
        "\r\n",
        "# plt.figure(figsize=(20,15))\r\n",
        "# for r in range(batch_size):\r\n",
        "#     plt.subplot(4,8,r+1)\r\n",
        "#     f= plt.imshow(images[r].permute(2,1,0))\r\n",
        "#     plt.title(labels[r].item())\r\n",
        "# plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAbIU50Q_u2J"
      },
      "source": [
        "class Residual_Block(nn.Module):\r\n",
        "  def __init__(self, in_channels, out_channels, identity_downsample= None, stride=1):\r\n",
        "    super(Residual_Block,self).__init__()\r\n",
        "    self.expn= 4\r\n",
        "    self.conv1= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\r\n",
        "    self.bn1= nn.BatchNorm2d(num_features=out_channels)\r\n",
        "    self.conv2= nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1)\r\n",
        "    self.bn2= nn.BatchNorm2d(num_features=out_channels)\r\n",
        "    self.conv3= nn.Conv2d(in_channels= out_channels, out_channels=out_channels*self.expn, kernel_size=1, stride=1, padding=0)\r\n",
        "    self.bn3= nn.BatchNorm2d(num_features=out_channels*self.expn)\r\n",
        "    self.relu= nn.ReLU()\r\n",
        "    self.identity_downsample= identity_downsample\r\n",
        "\r\n",
        "  def forward(self,x):\r\n",
        "\r\n",
        "    identity=x\r\n",
        "    x= nn.Sequential(self.conv1,\r\n",
        "                     self.bn1,\r\n",
        "                     self.conv2,\r\n",
        "                     self.bn2,\r\n",
        "                     self.conv3,\r\n",
        "                     self.bn3)(x)\r\n",
        "    if self.identity_downsample is not None:\r\n",
        "      identity= self.identity_downsample(identity)\r\n",
        "    \r\n",
        "    x-= identity\r\n",
        "    x=self.relu(x)\r\n",
        "    \r\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu3tkRKc_0Uw"
      },
      "source": [
        "class ResNet(nn.Module):\r\n",
        "  def __init__(self, Residual_Block, layers, image_channels, num_classes):\r\n",
        "    super(ResNet,self).__init__()\r\n",
        "    self.in_channels=64\r\n",
        "    self.conv1= nn.Conv2d(in_channels=image_channels, out_channels=64, kernel_size=7, stride=2, padding=3)\r\n",
        "    self.bn1= nn.BatchNorm2d(num_features= 64)\r\n",
        "    self.relu= nn.ReLU()\r\n",
        "    self.maxpool= nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "\r\n",
        "    self.layer_1= self._make_layer(Residual_Block, layers[0], out_channels=64, stride=1)\r\n",
        "    self.layer_2= self._make_layer(Residual_Block, layers[1], out_channels=128, stride=2)\r\n",
        "    self.layer_3= self._make_layer(Residual_Block, layers[2], out_channels=256, stride=2)\r\n",
        "    self.layer_4= self._make_layer(Residual_Block, layers[3], out_channels=512, stride=2)\r\n",
        "\r\n",
        "    self.avgpool= nn.AdaptiveAvgPool2d((1,1))\r\n",
        "    self.fc= nn.Linear(512*4, num_classes)\r\n",
        "\r\n",
        "  def forward(self,x):\r\n",
        "    x= nn.Sequential(self.conv1,\r\n",
        "                         self.bn1,\r\n",
        "                         self.relu,\r\n",
        "                         self.maxpool,\r\n",
        "                         self.layer_1,\r\n",
        "                         self.layer_2,\r\n",
        "                         self.layer_3,\r\n",
        "                         self.layer_4,\r\n",
        "                         self.avgpool)(x)\r\n",
        "    x= x.reshape(x.shape[0], -1)\r\n",
        "    x= self.fc(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "  def _make_layer(self,Residual_Block, num_res_blocks, out_channels, stride):\r\n",
        "    identity_downsample= None\r\n",
        "    layers=[]\r\n",
        "\r\n",
        "    if stride!=1 or self.in_channels!=out_channels*4:\r\n",
        "      identity_downsample= nn.Sequential(nn.Conv2d(in_channels=self.in_channels,\r\n",
        "                                                   out_channels= out_channels*4,\r\n",
        "                                                   kernel_size=1,\r\n",
        "                                                   stride=stride),\r\n",
        "                                         nn.BatchNorm2d(out_channels*4))\r\n",
        "    layers.append(Residual_Block(self.in_channels, out_channels, identity_downsample, stride))\r\n",
        "    self.in_channels= out_channels*4\r\n",
        "\r\n",
        "    for i in range(num_res_blocks-1):\r\n",
        "      layers.append(Residual_Block(self.in_channels, out_channels))\r\n",
        "    return nn.Sequential(*layers)\r\n",
        "\r\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMSZVYzAOsO",
        "outputId": "9d3ea3c3-95fc-411a-d4ae-60f0f9aa4ff5"
      },
      "source": [
        "def ResNet50(img_channels=3, num_classes=10):\r\n",
        "  return ResNet(Residual_Block, layers, img_channels, num_classes)\r\n",
        "\r\n",
        "model= ResNet50(img_channels=input_shape[0], num_classes=num_classes).to(device)\r\n",
        "summary(model, input_size= input_shape, batch_size=batch_size, device=device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [32, 64, 112, 112]           9,472\n",
            "       BatchNorm2d-2         [32, 64, 112, 112]             128\n",
            "              ReLU-3         [32, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [32, 64, 56, 56]               0\n",
            "            Conv2d-5           [32, 64, 56, 56]           4,160\n",
            "       BatchNorm2d-6           [32, 64, 56, 56]             128\n",
            "            Conv2d-7           [32, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-8           [32, 64, 56, 56]             128\n",
            "            Conv2d-9          [32, 256, 56, 56]          16,640\n",
            "      BatchNorm2d-10          [32, 256, 56, 56]             512\n",
            "           Conv2d-11          [32, 256, 56, 56]          16,640\n",
            "      BatchNorm2d-12          [32, 256, 56, 56]             512\n",
            "             ReLU-13          [32, 256, 56, 56]               0\n",
            "   Residual_Block-14          [32, 256, 56, 56]               0\n",
            "           Conv2d-15           [32, 64, 56, 56]          16,448\n",
            "      BatchNorm2d-16           [32, 64, 56, 56]             128\n",
            "           Conv2d-17           [32, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-18           [32, 64, 56, 56]             128\n",
            "           Conv2d-19          [32, 256, 56, 56]          16,640\n",
            "      BatchNorm2d-20          [32, 256, 56, 56]             512\n",
            "             ReLU-21          [32, 256, 56, 56]               0\n",
            "   Residual_Block-22          [32, 256, 56, 56]               0\n",
            "           Conv2d-23           [32, 64, 56, 56]          16,448\n",
            "      BatchNorm2d-24           [32, 64, 56, 56]             128\n",
            "           Conv2d-25           [32, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-26           [32, 64, 56, 56]             128\n",
            "           Conv2d-27          [32, 256, 56, 56]          16,640\n",
            "      BatchNorm2d-28          [32, 256, 56, 56]             512\n",
            "             ReLU-29          [32, 256, 56, 56]               0\n",
            "   Residual_Block-30          [32, 256, 56, 56]               0\n",
            "           Conv2d-31          [32, 128, 56, 56]          32,896\n",
            "      BatchNorm2d-32          [32, 128, 56, 56]             256\n",
            "           Conv2d-33          [32, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-34          [32, 128, 28, 28]             256\n",
            "           Conv2d-35          [32, 512, 28, 28]          66,048\n",
            "      BatchNorm2d-36          [32, 512, 28, 28]           1,024\n",
            "           Conv2d-37          [32, 512, 28, 28]         131,584\n",
            "      BatchNorm2d-38          [32, 512, 28, 28]           1,024\n",
            "             ReLU-39          [32, 512, 28, 28]               0\n",
            "   Residual_Block-40          [32, 512, 28, 28]               0\n",
            "           Conv2d-41          [32, 128, 28, 28]          65,664\n",
            "      BatchNorm2d-42          [32, 128, 28, 28]             256\n",
            "           Conv2d-43          [32, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-44          [32, 128, 28, 28]             256\n",
            "           Conv2d-45          [32, 512, 28, 28]          66,048\n",
            "      BatchNorm2d-46          [32, 512, 28, 28]           1,024\n",
            "             ReLU-47          [32, 512, 28, 28]               0\n",
            "   Residual_Block-48          [32, 512, 28, 28]               0\n",
            "           Conv2d-49          [32, 128, 28, 28]          65,664\n",
            "      BatchNorm2d-50          [32, 128, 28, 28]             256\n",
            "           Conv2d-51          [32, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-52          [32, 128, 28, 28]             256\n",
            "           Conv2d-53          [32, 512, 28, 28]          66,048\n",
            "      BatchNorm2d-54          [32, 512, 28, 28]           1,024\n",
            "             ReLU-55          [32, 512, 28, 28]               0\n",
            "   Residual_Block-56          [32, 512, 28, 28]               0\n",
            "           Conv2d-57          [32, 128, 28, 28]          65,664\n",
            "      BatchNorm2d-58          [32, 128, 28, 28]             256\n",
            "           Conv2d-59          [32, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-60          [32, 128, 28, 28]             256\n",
            "           Conv2d-61          [32, 512, 28, 28]          66,048\n",
            "      BatchNorm2d-62          [32, 512, 28, 28]           1,024\n",
            "             ReLU-63          [32, 512, 28, 28]               0\n",
            "   Residual_Block-64          [32, 512, 28, 28]               0\n",
            "           Conv2d-65          [32, 256, 28, 28]         131,328\n",
            "      BatchNorm2d-66          [32, 256, 28, 28]             512\n",
            "           Conv2d-67          [32, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-68          [32, 256, 14, 14]             512\n",
            "           Conv2d-69         [32, 1024, 14, 14]         263,168\n",
            "      BatchNorm2d-70         [32, 1024, 14, 14]           2,048\n",
            "           Conv2d-71         [32, 1024, 14, 14]         525,312\n",
            "      BatchNorm2d-72         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-73         [32, 1024, 14, 14]               0\n",
            "   Residual_Block-74         [32, 1024, 14, 14]               0\n",
            "           Conv2d-75          [32, 256, 14, 14]         262,400\n",
            "      BatchNorm2d-76          [32, 256, 14, 14]             512\n",
            "           Conv2d-77          [32, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-78          [32, 256, 14, 14]             512\n",
            "           Conv2d-79         [32, 1024, 14, 14]         263,168\n",
            "      BatchNorm2d-80         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-81         [32, 1024, 14, 14]               0\n",
            "   Residual_Block-82         [32, 1024, 14, 14]               0\n",
            "           Conv2d-83          [32, 256, 14, 14]         262,400\n",
            "      BatchNorm2d-84          [32, 256, 14, 14]             512\n",
            "           Conv2d-85          [32, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-86          [32, 256, 14, 14]             512\n",
            "           Conv2d-87         [32, 1024, 14, 14]         263,168\n",
            "      BatchNorm2d-88         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [32, 1024, 14, 14]               0\n",
            "   Residual_Block-90         [32, 1024, 14, 14]               0\n",
            "           Conv2d-91          [32, 256, 14, 14]         262,400\n",
            "      BatchNorm2d-92          [32, 256, 14, 14]             512\n",
            "           Conv2d-93          [32, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-94          [32, 256, 14, 14]             512\n",
            "           Conv2d-95         [32, 1024, 14, 14]         263,168\n",
            "      BatchNorm2d-96         [32, 1024, 14, 14]           2,048\n",
            "             ReLU-97         [32, 1024, 14, 14]               0\n",
            "   Residual_Block-98         [32, 1024, 14, 14]               0\n",
            "           Conv2d-99          [32, 256, 14, 14]         262,400\n",
            "     BatchNorm2d-100          [32, 256, 14, 14]             512\n",
            "          Conv2d-101          [32, 256, 14, 14]         590,080\n",
            "     BatchNorm2d-102          [32, 256, 14, 14]             512\n",
            "          Conv2d-103         [32, 1024, 14, 14]         263,168\n",
            "     BatchNorm2d-104         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-105         [32, 1024, 14, 14]               0\n",
            "  Residual_Block-106         [32, 1024, 14, 14]               0\n",
            "          Conv2d-107          [32, 256, 14, 14]         262,400\n",
            "     BatchNorm2d-108          [32, 256, 14, 14]             512\n",
            "          Conv2d-109          [32, 256, 14, 14]         590,080\n",
            "     BatchNorm2d-110          [32, 256, 14, 14]             512\n",
            "          Conv2d-111         [32, 1024, 14, 14]         263,168\n",
            "     BatchNorm2d-112         [32, 1024, 14, 14]           2,048\n",
            "            ReLU-113         [32, 1024, 14, 14]               0\n",
            "  Residual_Block-114         [32, 1024, 14, 14]               0\n",
            "          Conv2d-115          [32, 512, 14, 14]         524,800\n",
            "     BatchNorm2d-116          [32, 512, 14, 14]           1,024\n",
            "          Conv2d-117            [32, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-118            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-119           [32, 2048, 7, 7]       1,050,624\n",
            "     BatchNorm2d-120           [32, 2048, 7, 7]           4,096\n",
            "          Conv2d-121           [32, 2048, 7, 7]       2,099,200\n",
            "     BatchNorm2d-122           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-123           [32, 2048, 7, 7]               0\n",
            "  Residual_Block-124           [32, 2048, 7, 7]               0\n",
            "          Conv2d-125            [32, 512, 7, 7]       1,049,088\n",
            "     BatchNorm2d-126            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-127            [32, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-128            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-129           [32, 2048, 7, 7]       1,050,624\n",
            "     BatchNorm2d-130           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-131           [32, 2048, 7, 7]               0\n",
            "  Residual_Block-132           [32, 2048, 7, 7]               0\n",
            "          Conv2d-133            [32, 512, 7, 7]       1,049,088\n",
            "     BatchNorm2d-134            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-135            [32, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-136            [32, 512, 7, 7]           1,024\n",
            "          Conv2d-137           [32, 2048, 7, 7]       1,050,624\n",
            "     BatchNorm2d-138           [32, 2048, 7, 7]           4,096\n",
            "            ReLU-139           [32, 2048, 7, 7]               0\n",
            "  Residual_Block-140           [32, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-141           [32, 2048, 1, 1]               0\n",
            "          Linear-142                    [32, 4]           8,196\n",
            "================================================================\n",
            "Total params: 23,542,788\n",
            "Trainable params: 23,542,788\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 18.38\n",
            "Forward/backward pass size (MB): 8367.25\n",
            "Params size (MB): 89.81\n",
            "Estimated Total Size (MB): 8475.43\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64iVEIrkuO_l"
      },
      "source": [
        "Loss= nn.CrossEntropyLoss()\r\n",
        "optimizer= optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8_tWGcWu9v2"
      },
      "source": [
        "def check_accuracy(scores, targets):\r\n",
        "\r\n",
        "  num_correct=0\r\n",
        "  num_samples=0\r\n",
        "  _, predictions= scores.max(1)\r\n",
        "  num_correct+= (predictions== targets).sum()\r\n",
        "  num_samples= predictions.size(0)\r\n",
        "\r\n",
        "  return num_correct/num_samples"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F81oPGN8duv-"
      },
      "source": [
        "def save_checkpoint(model, optimizer, file_name):\r\n",
        "\r\n",
        "  checkpoint= {'state_dict': model.state_dict(),\r\n",
        "             'optimizer_dict': optimizer.state_dict()}\r\n",
        "  torch.save(checkpoint,file_name)\r\n",
        "\r\n",
        "def load_checkpoint(model, optimizer, file_name):\r\n",
        "  check_pt= torch.load(file_name)\r\n",
        "  model.load_state_dict(check_pt['state_dict'])\r\n",
        "  optimizer.load_state_dict(check_pt['optimizer_dict'])\r\n",
        "\r\n",
        "  return model, optimizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPowtOToAtic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed12f42-1a6c-471a-9e52-ac2a4d5a2b22"
      },
      "source": [
        "train_per_epoch= len(train_loader)\r\n",
        "val_per_epoch= len(val_loader)\r\n",
        "min_loss= math.inf\r\n",
        "min_loss\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "  train_losses=[]\r\n",
        "### TRAINING\r\n",
        "\r\n",
        "  kbar_train= pkbar.Kbar(target= train_per_epoch, epoch=epoch, num_epochs=num_epochs)\r\n",
        "\r\n",
        "  train_loop= enumerate(train_loader)\r\n",
        "  val_loop= enumerate(val_loader)\r\n",
        "  for batch_idx, (data,targets) in train_loop:\r\n",
        "\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    data= data.to(device=device)\r\n",
        "    targets= targets.to(device=device)\r\n",
        "\r\n",
        "    # FORWARD PROP\r\n",
        "\r\n",
        "    scores= model(data)\r\n",
        "    train_loss= Loss(scores, targets)\r\n",
        "    train_losses.append(train_loss.item())\r\n",
        "\r\n",
        "    # BACKWARD PROP\r\n",
        "    optimizer.zero_grad()\r\n",
        "    train_loss.backward()\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    train_acc= check_accuracy(scores,targets)\r\n",
        "\r\n",
        "    kbar_train.update(batch_idx, values=[(\"loss\", train_loss.item()), (\"accuracy\", train_acc.item())])\r\n",
        "\r\n",
        "  kbar_train.update(train_per_epoch, values=None)\r\n",
        "### VALIDATION\r\n",
        "\r\n",
        "  kbar_val= pkbar.Kbar(target= val_per_epoch, epoch=epoch, num_epochs=num_epochs)\r\n",
        "\r\n",
        "\r\n",
        "  for batch_idx, (data, targets) in val_loop:\r\n",
        "\r\n",
        "    val_losses=[]\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    \r\n",
        "    data= data.to(device=device)\r\n",
        "    targets= targets.to(device=device)\r\n",
        "    scores= model(data)\r\n",
        "    val_loss= Loss(scores, targets)\r\n",
        "    val_losses.append(val_loss.item())\r\n",
        "    val_acc= check_accuracy(scores,targets)\r\n",
        "\r\n",
        "    kbar_val.update(batch_idx, values=[(\"val_loss\", val_loss.item()), (\"val_accuracy\", val_acc.item())])\r\n",
        "\r\n",
        "  if np.mean(val_losses)<min_loss:\r\n",
        "    min_loss= val_loss.item()\r\n",
        "    print('\\nImproved validation loss: {:.4f}'.format(val_loss.item()))\r\n",
        "    print('Saving the model to {}\\n'.format(check_pt_file))\r\n",
        "    save_checkpoint(model, optimizer, check_pt_file)\r\n",
        "    \r\n",
        "  kbar_val.update(val_per_epoch, values=None)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/100\n",
            "83/83 [==============================] - 1814s 22s/step - loss: 0.9441 - accuracy: 0.5685\n",
            "Epoch: 1/100\n",
            "8/9 [=========================>....] - ETA: 22s - val_loss: 0.8233 - val_accuracy: 0.6198\n",
            "Improved validation loss: 0.7582\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_3.pth.tar\n",
            "\n",
            "9/9 [==============================] - 183s 20s/step - val_loss: 0.8233 - val_accuracy: 0.6198\n",
            "Epoch: 2/100\n",
            "83/83 [==============================] - 34s 415ms/step - loss: 0.6891 - accuracy: 0.6743\n",
            "Epoch: 2/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.7831 - val_accuracy: 0.6497\n",
            "Improved validation loss: 0.6745\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_3.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 359ms/step - val_loss: 0.7831 - val_accuracy: 0.6497\n",
            "Epoch: 3/100\n",
            "83/83 [==============================] - 34s 413ms/step - loss: 0.6207 - accuracy: 0.6958\n",
            "Epoch: 3/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.8021 - val_accuracy: 0.5885\n",
            "Improved validation loss: 0.6389\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_3.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 331ms/step - val_loss: 0.8021 - val_accuracy: 0.5885\n",
            "Epoch: 4/100\n",
            "83/83 [==============================] - 35s 418ms/step - loss: 0.5306 - accuracy: 0.7576\n",
            "Epoch: 4/100\n",
            "9/9 [==============================] - 2s 208ms/step - val_loss: 0.9096 - val_accuracy: 0.5625\n",
            "Epoch: 5/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.5041 - accuracy: 0.7675\n",
            "Epoch: 5/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 1.0792 - val_accuracy: 0.5469\n",
            "Epoch: 6/100\n",
            "83/83 [==============================] - 34s 414ms/step - loss: 0.4651 - accuracy: 0.7988\n",
            "Epoch: 6/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.4109 - val_accuracy: 0.8125\n",
            "Improved validation loss: 0.2546\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_3.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 342ms/step - val_loss: 0.4109 - val_accuracy: 0.8125\n",
            "Epoch: 7/100\n",
            "83/83 [==============================] - 34s 415ms/step - loss: 0.3984 - accuracy: 0.8218\n",
            "Epoch: 7/100\n",
            "9/9 [==============================] - 2s 197ms/step - val_loss: 0.6925 - val_accuracy: 0.6497\n",
            "Epoch: 8/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.3755 - accuracy: 0.8441\n",
            "Epoch: 8/100\n",
            "9/9 [==============================] - 2s 202ms/step - val_loss: 0.5675 - val_accuracy: 0.7617\n",
            "Epoch: 9/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.3680 - accuracy: 0.8483\n",
            "Epoch: 9/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 1.2780 - val_accuracy: 0.6445\n",
            "Epoch: 10/100\n",
            "83/83 [==============================] - 34s 414ms/step - loss: 0.3171 - accuracy: 0.8726\n",
            "Epoch: 10/100\n",
            "9/9 [==============================] - 2s 202ms/step - val_loss: 0.8167 - val_accuracy: 0.6693\n",
            "Epoch: 11/100\n",
            "83/83 [==============================] - 34s 411ms/step - loss: 0.2753 - accuracy: 0.8839\n",
            "Epoch: 11/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 0.5266 - val_accuracy: 0.7878\n",
            "Epoch: 12/100\n",
            "83/83 [==============================] - 34s 410ms/step - loss: 0.3111 - accuracy: 0.8654\n",
            "Epoch: 12/100\n",
            "9/9 [==============================] - 2s 202ms/step - val_loss: 0.6227 - val_accuracy: 0.7240\n",
            "Epoch: 13/100\n",
            "83/83 [==============================] - 35s 416ms/step - loss: 0.2890 - accuracy: 0.8846\n",
            "Epoch: 13/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 0.7404 - val_accuracy: 0.8008\n",
            "Epoch: 14/100\n",
            "83/83 [==============================] - 34s 415ms/step - loss: 0.2349 - accuracy: 0.9006\n",
            "Epoch: 14/100\n",
            "9/9 [==============================] - 2s 220ms/step - val_loss: 0.5757 - val_accuracy: 0.7786\n",
            "Epoch: 15/100\n",
            "83/83 [==============================] - 35s 419ms/step - loss: 0.2229 - accuracy: 0.9104\n",
            "Epoch: 15/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.3143 - val_accuracy: 0.8581\n",
            "Improved validation loss: 0.1105\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_3.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 347ms/step - val_loss: 0.3143 - val_accuracy: 0.8581\n",
            "Epoch: 16/100\n",
            "83/83 [==============================] - 35s 422ms/step - loss: 0.2195 - accuracy: 0.9086\n",
            "Epoch: 16/100\n",
            "9/9 [==============================] - 2s 201ms/step - val_loss: 1.4976 - val_accuracy: 0.6940\n",
            "Epoch: 17/100\n",
            "83/83 [==============================] - 35s 423ms/step - loss: 0.1846 - accuracy: 0.9265\n",
            "Epoch: 17/100\n",
            "9/9 [==============================] - 2s 203ms/step - val_loss: 0.5228 - val_accuracy: 0.7799\n",
            "Epoch: 18/100\n",
            "83/83 [==============================] - 35s 420ms/step - loss: 0.2511 - accuracy: 0.9002\n",
            "Epoch: 18/100\n",
            "9/9 [==============================] - 2s 208ms/step - val_loss: 2.0696 - val_accuracy: 0.6445\n",
            "Epoch: 19/100\n",
            "83/83 [==============================] - 35s 420ms/step - loss: 0.2142 - accuracy: 0.9111\n",
            "Epoch: 19/100\n",
            "9/9 [==============================] - 2s 203ms/step - val_loss: 0.8723 - val_accuracy: 0.7448\n",
            "Epoch: 20/100\n",
            "83/83 [==============================] - 35s 416ms/step - loss: 0.2079 - accuracy: 0.9156\n",
            "Epoch: 20/100\n",
            "9/9 [==============================] - 2s 207ms/step - val_loss: 0.3039 - val_accuracy: 0.8477\n",
            "Epoch: 21/100\n",
            "83/83 [==============================] - 35s 417ms/step - loss: 0.1796 - accuracy: 0.9291\n",
            "Epoch: 21/100\n",
            "9/9 [==============================] - 2s 212ms/step - val_loss: 0.4411 - val_accuracy: 0.8581\n",
            "Epoch: 22/100\n",
            "83/83 [==============================] - 35s 419ms/step - loss: 0.1557 - accuracy: 0.9343\n",
            "Epoch: 22/100\n",
            "9/9 [==============================] - 2s 202ms/step - val_loss: 0.4917 - val_accuracy: 0.8568\n",
            "Epoch: 23/100\n",
            "83/83 [==============================] - 34s 412ms/step - loss: 0.1952 - accuracy: 0.9197\n",
            "Epoch: 23/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 0.5694 - val_accuracy: 0.8242\n",
            "Epoch: 24/100\n",
            "83/83 [==============================] - 34s 415ms/step - loss: 0.1903 - accuracy: 0.9261\n",
            "Epoch: 24/100\n",
            "9/9 [==============================] - 2s 204ms/step - val_loss: 0.4177 - val_accuracy: 0.8828\n",
            "Epoch: 25/100\n",
            "83/83 [==============================] - 34s 411ms/step - loss: 0.1382 - accuracy: 0.9486\n",
            "Epoch: 25/100\n",
            "9/9 [==============================] - 2s 205ms/step - val_loss: 0.7378 - val_accuracy: 0.7422\n",
            "Epoch: 26/100\n",
            "83/83 [==============================] - 34s 415ms/step - loss: 0.1389 - accuracy: 0.9454\n",
            "Epoch: 26/100\n",
            "9/9 [==============================] - 2s 215ms/step - val_loss: 0.6512 - val_accuracy: 0.8203\n",
            "Epoch: 27/100\n",
            "83/83 [==============================] - 34s 414ms/step - loss: 0.1534 - accuracy: 0.9425\n",
            "Epoch: 27/100\n",
            "9/9 [==============================] - 2s 201ms/step - val_loss: 0.9448 - val_accuracy: 0.7552\n",
            "Epoch: 28/100\n",
            "83/83 [==============================] - 34s 413ms/step - loss: 0.1496 - accuracy: 0.9366\n",
            "Epoch: 28/100\n",
            "9/9 [==============================] - 2s 201ms/step - val_loss: 1.0356 - val_accuracy: 0.7266\n",
            "Epoch: 29/100\n",
            "83/83 [==============================] - 34s 413ms/step - loss: 0.1406 - accuracy: 0.9442\n",
            "Epoch: 29/100\n",
            "9/9 [==============================] - 2s 208ms/step - val_loss: 0.6623 - val_accuracy: 0.7917\n",
            "Epoch: 30/100\n",
            "83/83 [==============================] - 35s 420ms/step - loss: 0.1393 - accuracy: 0.9440\n",
            "Epoch: 30/100\n",
            "9/9 [==============================] - 2s 208ms/step - val_loss: 1.1712 - val_accuracy: 0.6523\n",
            "Epoch: 31/100\n",
            "83/83 [==============================] - 34s 411ms/step - loss: 0.1495 - accuracy: 0.9436\n",
            "Epoch: 31/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 0.7902 - val_accuracy: 0.7669\n",
            "Epoch: 32/100\n",
            "83/83 [==============================] - 34s 410ms/step - loss: 0.0958 - accuracy: 0.9631\n",
            "Epoch: 32/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 0.4546 - val_accuracy: 0.8685\n",
            "Epoch: 33/100\n",
            "83/83 [==============================] - 34s 410ms/step - loss: 0.1555 - accuracy: 0.9379\n",
            "Epoch: 33/100\n",
            "9/9 [==============================] - 2s 205ms/step - val_loss: 3.3681 - val_accuracy: 0.4583\n",
            "Epoch: 34/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.1182 - accuracy: 0.9535\n",
            "Epoch: 34/100\n",
            "9/9 [==============================] - 2s 205ms/step - val_loss: 0.4952 - val_accuracy: 0.8307\n",
            "Epoch: 35/100\n",
            "83/83 [==============================] - 34s 410ms/step - loss: 0.0953 - accuracy: 0.9630\n",
            "Epoch: 35/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.5302 - val_accuracy: 0.8451\n",
            "Epoch: 36/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.1066 - accuracy: 0.9595\n",
            "Epoch: 36/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 1.3472 - val_accuracy: 0.7370\n",
            "Epoch: 37/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0979 - accuracy: 0.9658\n",
            "Epoch: 37/100\n",
            "9/9 [==============================] - 2s 195ms/step - val_loss: 0.4614 - val_accuracy: 0.8659\n",
            "Epoch: 38/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.1100 - accuracy: 0.9619\n",
            "Epoch: 38/100\n",
            "9/9 [==============================] - 2s 206ms/step - val_loss: 1.1739 - val_accuracy: 0.7292\n",
            "Epoch: 39/100\n",
            "83/83 [==============================] - 34s 412ms/step - loss: 0.1069 - accuracy: 0.9621\n",
            "Epoch: 39/100\n",
            "9/9 [==============================] - 2s 203ms/step - val_loss: 0.7377 - val_accuracy: 0.8151\n",
            "Epoch: 40/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.1149 - accuracy: 0.9572\n",
            "Epoch: 40/100\n",
            "9/9 [==============================] - 2s 205ms/step - val_loss: 2.9205 - val_accuracy: 0.5846\n",
            "Epoch: 41/100\n",
            "83/83 [==============================] - 34s 407ms/step - loss: 0.0830 - accuracy: 0.9703\n",
            "Epoch: 41/100\n",
            "9/9 [==============================] - 2s 202ms/step - val_loss: 1.2349 - val_accuracy: 0.7161\n",
            "Epoch: 42/100\n",
            "83/83 [==============================] - 34s 410ms/step - loss: 0.0684 - accuracy: 0.9741\n",
            "Epoch: 42/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 0.7449 - val_accuracy: 0.8190\n",
            "Epoch: 43/100\n",
            "83/83 [==============================] - 34s 407ms/step - loss: 0.0768 - accuracy: 0.9710\n",
            "Epoch: 43/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 1.3591 - val_accuracy: 0.7357\n",
            "Epoch: 44/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0963 - accuracy: 0.9672\n",
            "Epoch: 44/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.7996 - val_accuracy: 0.8529\n",
            "Epoch: 45/100\n",
            "83/83 [==============================] - 34s 411ms/step - loss: 0.0799 - accuracy: 0.9703\n",
            "Epoch: 45/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.3975 - val_accuracy: 0.8555\n",
            "Epoch: 46/100\n",
            "83/83 [==============================] - 34s 410ms/step - loss: 0.0848 - accuracy: 0.9722\n",
            "Epoch: 46/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.4585 - val_accuracy: 0.8646\n",
            "Epoch: 47/100\n",
            "83/83 [==============================] - 34s 414ms/step - loss: 0.0827 - accuracy: 0.9682\n",
            "Epoch: 47/100\n",
            "9/9 [==============================] - 2s 196ms/step - val_loss: 0.5239 - val_accuracy: 0.8333\n",
            "Epoch: 48/100\n",
            "83/83 [==============================] - 34s 407ms/step - loss: 0.0834 - accuracy: 0.9734\n",
            "Epoch: 48/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 2.1390 - val_accuracy: 0.6276\n",
            "Epoch: 49/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.1229 - accuracy: 0.9531\n",
            "Epoch: 49/100\n",
            "9/9 [==============================] - 2s 196ms/step - val_loss: 1.7366 - val_accuracy: 0.7422\n",
            "Epoch: 50/100\n",
            "83/83 [==============================] - 34s 407ms/step - loss: 0.0796 - accuracy: 0.9701\n",
            "Epoch: 50/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 1.7897 - val_accuracy: 0.6810\n",
            "Epoch: 51/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0765 - accuracy: 0.9731\n",
            "Epoch: 51/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 1.2280 - val_accuracy: 0.7630\n",
            "Epoch: 52/100\n",
            "83/83 [==============================] - 34s 407ms/step - loss: 0.1162 - accuracy: 0.9578\n",
            "Epoch: 52/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 0.8173 - val_accuracy: 0.8242\n",
            "Epoch: 53/100\n",
            "83/83 [==============================] - 34s 411ms/step - loss: 0.0601 - accuracy: 0.9770\n",
            "Epoch: 53/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 0.7727 - val_accuracy: 0.8242\n",
            "Epoch: 54/100\n",
            "83/83 [==============================] - 34s 407ms/step - loss: 0.0679 - accuracy: 0.9771\n",
            "Epoch: 54/100\n",
            "9/9 [==============================] - 2s 201ms/step - val_loss: 0.5277 - val_accuracy: 0.8190\n",
            "Epoch: 55/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0685 - accuracy: 0.9760\n",
            "Epoch: 55/100\n",
            "9/9 [==============================] - 2s 214ms/step - val_loss: 0.6355 - val_accuracy: 0.8346\n",
            "Epoch: 56/100\n",
            "83/83 [==============================] - 34s 413ms/step - loss: 0.0623 - accuracy: 0.9762\n",
            "Epoch: 56/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 0.7879 - val_accuracy: 0.8685\n",
            "Epoch: 57/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0774 - accuracy: 0.9755\n",
            "Epoch: 57/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 1.0662 - val_accuracy: 0.7839\n",
            "Epoch: 58/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0590 - accuracy: 0.9786\n",
            "Epoch: 58/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.6238 - val_accuracy: 0.8359\n",
            "Epoch: 59/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0409 - accuracy: 0.9878\n",
            "Epoch: 59/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 1.2446 - val_accuracy: 0.7760\n",
            "Epoch: 60/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0652 - accuracy: 0.9787\n",
            "Epoch: 60/100\n",
            "9/9 [==============================] - 2s 211ms/step - val_loss: 1.8492 - val_accuracy: 0.6276\n",
            "Epoch: 61/100\n",
            "83/83 [==============================] - 34s 407ms/step - loss: 0.0742 - accuracy: 0.9724\n",
            "Epoch: 61/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 1.0405 - val_accuracy: 0.8607\n",
            "Epoch: 62/100\n",
            "83/83 [==============================] - 34s 412ms/step - loss: 0.0707 - accuracy: 0.9725\n",
            "Epoch: 62/100\n",
            "9/9 [==============================] - 2s 197ms/step - val_loss: 0.4742 - val_accuracy: 0.8685\n",
            "Epoch: 63/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0691 - accuracy: 0.9779\n",
            "Epoch: 63/100\n",
            "9/9 [==============================] - 2s 196ms/step - val_loss: 2.5646 - val_accuracy: 0.6615\n",
            "Epoch: 64/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0531 - accuracy: 0.9840\n",
            "Epoch: 64/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.7522 - val_accuracy: 0.8138\n",
            "Epoch: 65/100\n",
            "83/83 [==============================] - 34s 413ms/step - loss: 0.0494 - accuracy: 0.9821\n",
            "Epoch: 65/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.7636 - val_accuracy: 0.8398\n",
            "Epoch: 66/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0657 - accuracy: 0.9756\n",
            "Epoch: 66/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 1.5379 - val_accuracy: 0.7148\n",
            "Epoch: 67/100\n",
            "83/83 [==============================] - 34s 414ms/step - loss: 0.0390 - accuracy: 0.9867\n",
            "Epoch: 67/100\n",
            "9/9 [==============================] - 2s 221ms/step - val_loss: 0.8407 - val_accuracy: 0.8060\n",
            "Epoch: 68/100\n",
            "83/83 [==============================] - 35s 416ms/step - loss: 0.0390 - accuracy: 0.9855\n",
            "Epoch: 68/100\n",
            "9/9 [==============================] - 2s 203ms/step - val_loss: 1.1724 - val_accuracy: 0.7852\n",
            "Epoch: 69/100\n",
            "83/83 [==============================] - 34s 412ms/step - loss: 0.0658 - accuracy: 0.9758\n",
            "Epoch: 69/100\n",
            "9/9 [==============================] - 2s 195ms/step - val_loss: 0.9358 - val_accuracy: 0.7826\n",
            "Epoch: 70/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0685 - accuracy: 0.9745\n",
            "Epoch: 70/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.7150 - val_accuracy: 0.8268\n",
            "Epoch: 71/100\n",
            "83/83 [==============================] - 34s 411ms/step - loss: 0.0463 - accuracy: 0.9848\n",
            "Epoch: 71/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.8045 - val_accuracy: 0.8398\n",
            "Epoch: 72/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0482 - accuracy: 0.9829\n",
            "Epoch: 72/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 1.1917 - val_accuracy: 0.7669\n",
            "Epoch: 73/100\n",
            "83/83 [==============================] - 34s 412ms/step - loss: 0.0498 - accuracy: 0.9829\n",
            "Epoch: 73/100\n",
            "9/9 [==============================] - 2s 207ms/step - val_loss: 0.6101 - val_accuracy: 0.8633\n",
            "Epoch: 74/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0737 - accuracy: 0.9714\n",
            "Epoch: 74/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 0.7618 - val_accuracy: 0.8229\n",
            "Epoch: 75/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0425 - accuracy: 0.9835\n",
            "Epoch: 75/100\n",
            "9/9 [==============================] - 2s 204ms/step - val_loss: 2.9186 - val_accuracy: 0.6536\n",
            "Epoch: 76/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0398 - accuracy: 0.9848\n",
            "Epoch: 76/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.6112 - val_accuracy: 0.8581\n",
            "Epoch: 77/100\n",
            "83/83 [==============================] - 34s 406ms/step - loss: 0.0552 - accuracy: 0.9817\n",
            "Epoch: 77/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 3.4517 - val_accuracy: 0.6589\n",
            "Epoch: 78/100\n",
            "83/83 [==============================] - 34s 407ms/step - loss: 0.0455 - accuracy: 0.9850\n",
            "Epoch: 78/100\n",
            "9/9 [==============================] - 2s 197ms/step - val_loss: 0.8831 - val_accuracy: 0.8112\n",
            "Epoch: 79/100\n",
            "83/83 [==============================] - 34s 407ms/step - loss: 0.0397 - accuracy: 0.9856\n",
            "Epoch: 79/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 0.5322 - val_accuracy: 0.8568\n",
            "Epoch: 80/100\n",
            "83/83 [==============================] - 34s 414ms/step - loss: 0.0513 - accuracy: 0.9824\n",
            "Epoch: 80/100\n",
            "9/9 [==============================] - 2s 232ms/step - val_loss: 0.5098 - val_accuracy: 0.8333\n",
            "Epoch: 81/100\n",
            "83/83 [==============================] - 34s 415ms/step - loss: 0.0419 - accuracy: 0.9878\n",
            "Epoch: 81/100\n",
            "9/9 [==============================] - 2s 202ms/step - val_loss: 0.9618 - val_accuracy: 0.7930\n",
            "Epoch: 82/100\n",
            "83/83 [==============================] - 35s 416ms/step - loss: 0.0304 - accuracy: 0.9897\n",
            "Epoch: 82/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 0.7214 - val_accuracy: 0.8581\n",
            "Epoch: 83/100\n",
            "83/83 [==============================] - 34s 410ms/step - loss: 0.0716 - accuracy: 0.9779\n",
            "Epoch: 83/100\n",
            "9/9 [==============================] - 2s 201ms/step - val_loss: 1.8300 - val_accuracy: 0.6784\n",
            "Epoch: 84/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0720 - accuracy: 0.9752\n",
            "Epoch: 84/100\n",
            "9/9 [==============================] - 2s 203ms/step - val_loss: 0.8230 - val_accuracy: 0.8047\n",
            "Epoch: 85/100\n",
            "83/83 [==============================] - 34s 410ms/step - loss: 0.0298 - accuracy: 0.9892\n",
            "Epoch: 85/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.5387 - val_accuracy: 0.8854\n",
            "Improved validation loss: 0.1022\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_3.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 339ms/step - val_loss: 0.5387 - val_accuracy: 0.8854\n",
            "Epoch: 86/100\n",
            "83/83 [==============================] - 34s 414ms/step - loss: 0.0354 - accuracy: 0.9888\n",
            "Epoch: 86/100\n",
            "9/9 [==============================] - 2s 203ms/step - val_loss: 0.9975 - val_accuracy: 0.8490\n",
            "Epoch: 87/100\n",
            "83/83 [==============================] - 34s 411ms/step - loss: 0.0208 - accuracy: 0.9918\n",
            "Epoch: 87/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 0.7920 - val_accuracy: 0.8867\n",
            "Epoch: 88/100\n",
            "83/83 [==============================] - 34s 411ms/step - loss: 0.0551 - accuracy: 0.9829\n",
            "Epoch: 88/100\n",
            "9/9 [==============================] - 2s 200ms/step - val_loss: 0.6461 - val_accuracy: 0.8424\n",
            "Epoch: 89/100\n",
            "83/83 [==============================] - 34s 412ms/step - loss: 0.0521 - accuracy: 0.9787\n",
            "Epoch: 89/100\n",
            "9/9 [==============================] - 2s 204ms/step - val_loss: 1.0315 - val_accuracy: 0.7656\n",
            "Epoch: 90/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0453 - accuracy: 0.9850\n",
            "Epoch: 90/100\n",
            "9/9 [==============================] - 2s 216ms/step - val_loss: 0.6443 - val_accuracy: 0.8971\n",
            "Epoch: 91/100\n",
            "83/83 [==============================] - 35s 419ms/step - loss: 0.0473 - accuracy: 0.9893\n",
            "Epoch: 91/100\n",
            "9/9 [==============================] - 2s 206ms/step - val_loss: 0.6676 - val_accuracy: 0.8659\n",
            "Epoch: 92/100\n",
            "83/83 [==============================] - 34s 415ms/step - loss: 0.0978 - accuracy: 0.9680\n",
            "Epoch: 92/100\n",
            "9/9 [==============================] - 2s 197ms/step - val_loss: 0.4488 - val_accuracy: 0.8711\n",
            "Epoch: 93/100\n",
            "83/83 [==============================] - 34s 410ms/step - loss: 0.0407 - accuracy: 0.9848\n",
            "Epoch: 93/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 1.6008 - val_accuracy: 0.7057\n",
            "Epoch: 94/100\n",
            "83/83 [==============================] - 34s 413ms/step - loss: 0.0603 - accuracy: 0.9771\n",
            "Epoch: 94/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 2.5807 - val_accuracy: 0.6849\n",
            "Epoch: 95/100\n",
            "83/83 [==============================] - 34s 412ms/step - loss: 0.0355 - accuracy: 0.9893\n",
            "Epoch: 95/100\n",
            "9/9 [==============================] - 2s 201ms/step - val_loss: 1.4304 - val_accuracy: 0.7292\n",
            "Epoch: 96/100\n",
            "83/83 [==============================] - 34s 414ms/step - loss: 0.0318 - accuracy: 0.9878\n",
            "Epoch: 96/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 0.6271 - val_accuracy: 0.8659\n",
            "Epoch: 97/100\n",
            "83/83 [==============================] - 34s 411ms/step - loss: 0.0245 - accuracy: 0.9926\n",
            "Epoch: 97/100\n",
            "9/9 [==============================] - 2s 198ms/step - val_loss: 0.7000 - val_accuracy: 0.8789\n",
            "Epoch: 98/100\n",
            "83/83 [==============================] - 34s 408ms/step - loss: 0.0271 - accuracy: 0.9912\n",
            "Epoch: 98/100\n",
            "9/9 [==============================] - 2s 197ms/step - val_loss: 2.5872 - val_accuracy: 0.6784\n",
            "Epoch: 99/100\n",
            "83/83 [==============================] - 34s 412ms/step - loss: 0.0448 - accuracy: 0.9825\n",
            "Epoch: 99/100\n",
            "9/9 [==============================] - 2s 199ms/step - val_loss: 0.5412 - val_accuracy: 0.8581\n",
            "Epoch: 100/100\n",
            "83/83 [==============================] - 34s 409ms/step - loss: 0.0318 - accuracy: 0.9877\n",
            "Epoch: 100/100\n",
            "8/9 [=========================>....] - ETA: 0s - val_loss: 0.4780 - val_accuracy: 0.8750\n",
            "Improved validation loss: 0.0030\n",
            "Saving the model to drive/My Drive/Hist_folder/KMC Dataset/ResNet50_Checkpoint_3.pth.tar\n",
            "\n",
            "9/9 [==============================] - 3s 333ms/step - val_loss: 0.4780 - val_accuracy: 0.8750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_YKfqi6JXq8"
      },
      "source": [
        "def CONFUSION_MATRIX(y_true, y_pred, class_labels, order=False):\r\n",
        "  \r\n",
        "  num_classes= len(class_labels)\r\n",
        "  num_examples= len(y_true)\r\n",
        "\r\n",
        "  if order is False:\r\n",
        "    new_labels= np.arange(num_classes)\r\n",
        "    \r\n",
        "    for i in range(num_examples):\r\n",
        "      y_true[i].item= np.where(class_labels==y_true[i])[0]\r\n",
        "      y_pred[i].item= np.where(class_labels==y_pred[i])[0]\r\n",
        "\r\n",
        "  mat= np.zeros((num_classes,num_classes), dtype=np.int)\r\n",
        "  \r\n",
        "  for i in range(num_examples):\r\n",
        "    true= np.uint8(y_true[i].item())\r\n",
        "    pred= np.uint8(y_pred[i].item())\r\n",
        "\r\n",
        "    mat[true,pred]+=1\r\n",
        "\r\n",
        "  return mat\r\n",
        "\r\n",
        "\r\n",
        "def precision_recall_f1(confusion_matrix):\r\n",
        "\r\n",
        "  num_classes= confusion_matrix.shape[0]\r\n",
        "  precision= np.zeros(num_classes, np.float64)\r\n",
        "  recall= np.zeros(num_classes, np.float64)\r\n",
        "  f1= np.zeros(num_classes, np.float64)\r\n",
        "\r\n",
        "  for i in range(num_classes):\r\n",
        "    \r\n",
        "    precision[i]= confusion_matrix[i,i]/np.sum(confusion_matrix[i])\r\n",
        "    recall[i]= confusion_matrix[i,i]/np.sum(confusion_matrix[:,i])\r\n",
        "    f1[i]= 2*precision[i]*recall[i]/(precision[i]+recall[i])\r\n",
        "\r\n",
        "\r\n",
        "  return precision, recall, f1\r\n",
        "\r\n",
        "\r\n",
        "def Final_Metrics(loader, model, class_labels):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    size= len(class_labels)\r\n",
        "    c_mat= np.zeros((size,size), dtype= np.int)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for x, y in loader:\r\n",
        "            x = x.to(device=device)\r\n",
        "            y = y.to(device=device)\r\n",
        "\r\n",
        "            scores= model(x)\r\n",
        "            _, preds = scores.max(1)\r\n",
        "\r\n",
        "            c_mat+= CONFUSION_MATRIX(y, preds, class_labels, order= True)\r\n",
        "    \r\n",
        "    precision, recall, f1= precision_recall_f1(c_mat)\r\n",
        "\r\n",
        "    return c_mat, np.mean(precision), np.mean(recall), np.mean(f1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8cRuzw9wVaK"
      },
      "source": [
        "resnet_50, _= load_checkpoint(model, optimizer, check_pt_file)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqdAZbNtudpl"
      },
      "source": [
        "confusion_matrix, precision, recall, f1= Final_Metrics(test_loader, resnet_50, class_labels)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcVhQQ8Hu5D6",
        "outputId": "9ea14a83-d5b7-4dea-e0c6-0e9be0540a9b"
      },
      "source": [
        "print(confusion_matrix)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[70  0  0  0]\n",
            " [ 0 76  4  0]\n",
            " [ 1 12 67  0]\n",
            " [ 0  5  5 40]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t93P6U8_vqEo",
        "outputId": "ba51eca7-1d0a-4f87-990d-22a4fc96eac9"
      },
      "source": [
        "precision"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8968750000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31oaOfIKvsnx",
        "outputId": "25d0ac6b-05df-4b77-8ab6-c034c3192c1c"
      },
      "source": [
        "recall"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9211746853503591"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5f_VjUyvvnR",
        "outputId": "66f8cd6d-6255-4909-9213-34be679a5125"
      },
      "source": [
        " f1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9048459415111734"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVXI6Yxbvyng",
        "outputId": "06952600-080a-4867-8672-66da2f57e454"
      },
      "source": [
        "np.sum(confusion_matrix)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMPXNPnjv02l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}