{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jyvQUouwF2Tn22a2ZghmXYx5NyaDkHuW",
      "authorship_tag": "ABX9TyPm+IWSkiNRaUCeFgGd7P9J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashrikant39/Histopatgology-Image-Classification/blob/main/ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOnzBnai_RVp"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision\r\n",
        "from torchsummary import summary\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import math\r\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm62yiRGGzFS"
      },
      "source": [
        "!pip install pkbar\r\n",
        "import pkbar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVoBgr3YAP9v"
      },
      "source": [
        "batch_size= 32\r\n",
        "device = 'cuda'\r\n",
        "num_classes= 4\r\n",
        "input_shape=(3,224,224)\r\n",
        "layers= [3,4,6,3]\r\n",
        "learning_rate=1e-4\r\n",
        "num_epochs= 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao3vjZ8nfaRy"
      },
      "source": [
        "main_path= 'drive/My Drive/Hist_folder/KMC Dataset'\r\n",
        "train_dir= os.path.join(main_path,'Training')\r\n",
        "test_dir= os.path.join(main_path,'Test')\r\n",
        "val_dir= os.path.join(main_path,'Validation')\r\n",
        "\r\n",
        "check_pt_file= os.path.join(main_path, 'ResNet50_Checkpoint_3.pth.tar')\r\n",
        "\r\n",
        "print(os.listdir(main_path))\r\n",
        "print(os.listdir(train_dir))\r\n",
        "print(os.listdir(test_dir))\r\n",
        "print(os.listdir(val_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSDTwhDqOG8m"
      },
      "source": [
        "my_transforms = transforms.Compose([ #Compose makes it possible to have many transforms\r\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3), # Change brightness of image\r\n",
        "    transforms.RandomRotation(degrees=45), # Perhaps a random rotation from -45 to 45 degrees\r\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # Flips the image horizontally with probability 0.5\r\n",
        "    transforms.RandomVerticalFlip(p=0.05), # Flips image vertically with probability 0.05\r\n",
        "    transforms.ToTensor() # Finally converts PIL image to tensor so we can train w. pytorch\r\n",
        "    ])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x2vEw-Tf_vk"
      },
      "source": [
        "train_data= datasets.ImageFolder(train_dir, transform= my_transforms)\r\n",
        "test_data= datasets.ImageFolder(test_dir, transform= transforms.ToTensor())\r\n",
        "val_data= datasets.ImageFolder(val_dir, transform= transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEDaY7p9gsEz"
      },
      "source": [
        "train_loader= DataLoader(train_data, batch_size=batch_size, shuffle=True)\r\n",
        "test_loader= DataLoader(test_data, batch_size=batch_size, shuffle=True)\r\n",
        "val_loader= DataLoader(val_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCHEpxdooz1E"
      },
      "source": [
        "class_dict=train_data.class_to_idx\r\n",
        "class_labels = class_dict.values()\r\n",
        "print(class_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWJYfR16O-0l"
      },
      "source": [
        "### Plotting the images with classes\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gIA-Bc-iKHT"
      },
      "source": [
        "iterator= iter(train_loader)\r\n",
        "it= next(iterator)\r\n",
        "images, labels= it\r\n",
        "\r\n",
        "plt.figure(figsize=(20,15))\r\n",
        "for r in range(batch_size):\r\n",
        "    plt.subplot(4,8,r+1)\r\n",
        "    f= plt.imshow(images[r].permute(2,1,0))\r\n",
        "    plt.title(labels[r].item())\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAbIU50Q_u2J"
      },
      "source": [
        "class Residual_Block(nn.Module):\r\n",
        "  def __init__(self, in_channels, out_channels, identity_downsample= None, stride=1):\r\n",
        "    super(Residual_Block,self).__init__()\r\n",
        "    self.expn= 4\r\n",
        "    self.conv1= nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\r\n",
        "    self.bn1= nn.BatchNorm2d(num_features=out_channels)\r\n",
        "    self.conv2= nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1)\r\n",
        "    self.bn2= nn.BatchNorm2d(num_features=out_channels)\r\n",
        "    self.conv3= nn.Conv2d(in_channels= out_channels, out_channels=out_channels*self.expn, kernel_size=1, stride=1, padding=0)\r\n",
        "    self.bn3= nn.BatchNorm2d(num_features=out_channels*self.expn)\r\n",
        "    self.relu= nn.ReLU()\r\n",
        "    self.identity_downsample= identity_downsample\r\n",
        "\r\n",
        "  def forward(self,x):\r\n",
        "\r\n",
        "    identity=x\r\n",
        "    x= nn.Sequential(self.conv1,\r\n",
        "                     self.bn1,\r\n",
        "                     self.conv2,\r\n",
        "                     self.bn2,\r\n",
        "                     self.conv3,\r\n",
        "                     self.bn3)(x)\r\n",
        "    if self.identity_downsample is not None:\r\n",
        "      identity= self.identity_downsample(identity)\r\n",
        "    \r\n",
        "    x-= identity\r\n",
        "    x=self.relu(x)\r\n",
        "    \r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu3tkRKc_0Uw"
      },
      "source": [
        "class ResNet(nn.Module):\r\n",
        "  def __init__(self, Residual_Block, layers, image_channels, num_classes):\r\n",
        "    super(ResNet,self).__init__()\r\n",
        "    self.in_channels=64\r\n",
        "    self.conv1= nn.Conv2d(in_channels=image_channels, out_channels=64, kernel_size=7, stride=2, padding=3)\r\n",
        "    self.bn1= nn.BatchNorm2d(num_features= 64)\r\n",
        "    self.relu= nn.ReLU()\r\n",
        "    self.maxpool= nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "\r\n",
        "    self.layer_1= self._make_layer(Residual_Block, layers[0], out_channels=64, stride=1)\r\n",
        "    self.layer_2= self._make_layer(Residual_Block, layers[1], out_channels=128, stride=2)\r\n",
        "    self.layer_3= self._make_layer(Residual_Block, layers[2], out_channels=256, stride=2)\r\n",
        "    self.layer_4= self._make_layer(Residual_Block, layers[3], out_channels=512, stride=2)\r\n",
        "\r\n",
        "    self.avgpool= nn.AdaptiveAvgPool2d((1,1))\r\n",
        "    self.fc= nn.Linear(512*4, num_classes)\r\n",
        "\r\n",
        "  def forward(self,x):\r\n",
        "    x= nn.Sequential(self.conv1,\r\n",
        "                         self.bn1,\r\n",
        "                         self.relu,\r\n",
        "                         self.maxpool,\r\n",
        "                         self.layer_1,\r\n",
        "                         self.layer_2,\r\n",
        "                         self.layer_3,\r\n",
        "                         self.layer_4,\r\n",
        "                         self.avgpool)(x)\r\n",
        "    x= x.reshape(x.shape[0], -1)\r\n",
        "    x= self.fc(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "  def _make_layer(self,Residual_Block, num_res_blocks, out_channels, stride):\r\n",
        "    identity_downsample= None\r\n",
        "    layers=[]\r\n",
        "\r\n",
        "    if stride!=1 or self.in_channels!=out_channels*4:\r\n",
        "      identity_downsample= nn.Sequential(nn.Conv2d(in_channels=self.in_channels,\r\n",
        "                                                   out_channels= out_channels*4,\r\n",
        "                                                   kernel_size=1,\r\n",
        "                                                   stride=stride),\r\n",
        "                                         nn.BatchNorm2d(out_channels*4))\r\n",
        "    layers.append(Residual_Block(self.in_channels, out_channels, identity_downsample, stride))\r\n",
        "    self.in_channels= out_channels*4\r\n",
        "\r\n",
        "    for i in range(num_res_blocks-1):\r\n",
        "      layers.append(Residual_Block(self.in_channels, out_channels))\r\n",
        "    return nn.Sequential(*layers)\r\n",
        "\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJMSZVYzAOsO"
      },
      "source": [
        "def ResNet50(img_channels=3, num_classes=10):\r\n",
        "  return ResNet(Residual_Block, layers, img_channels, num_classes)\r\n",
        "\r\n",
        "model= ResNet50(img_channels=input_shape[0], num_classes=num_classes).to(device)\r\n",
        "summary(model, input_size= input_shape, batch_size=batch_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64iVEIrkuO_l"
      },
      "source": [
        "Loss= nn.CrossEntropyLoss()\r\n",
        "optimizer= optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8_tWGcWu9v2"
      },
      "source": [
        "def check_accuracy(scores, targets):\r\n",
        "\r\n",
        "  num_correct=0\r\n",
        "  num_samples=0\r\n",
        "  _, predictions= scores.max(1)\r\n",
        "  num_correct+= (predictions== targets).sum()\r\n",
        "  num_samples= predictions.size(0)\r\n",
        "\r\n",
        "  return num_correct/num_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F81oPGN8duv-"
      },
      "source": [
        "def save_checkpoint(model, optimizer, file_name):\r\n",
        "\r\n",
        "  checkpoint= {'state_dict': model.state_dict(),\r\n",
        "             'optimizer_dict': optimizer.state_dict()}\r\n",
        "  torch.save(checkpoint,file_name)\r\n",
        "\r\n",
        "def load_checkpoint(model, optimizer, file_name):\r\n",
        "  check_pt= torch.load(file_name)\r\n",
        "  model.load_state_dict(check_pt['state_dict'])\r\n",
        "  optimizer.load_state_dict(check_pt['optimizer_dict'])\r\n",
        "\r\n",
        "  return model, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPowtOToAtic"
      },
      "source": [
        "train_per_epoch= len(train_loader)\r\n",
        "val_per_epoch= len(val_loader)\r\n",
        "min_loss= math.inf\r\n",
        "min_loss\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "  train_losses=[]\r\n",
        "### TRAINING\r\n",
        "\r\n",
        "  kbar_train= pkbar.Kbar(target= train_per_epoch, epoch=epoch, num_epochs=num_epochs)\r\n",
        "\r\n",
        "  train_loop= enumerate(train_loader)\r\n",
        "  val_loop= enumerate(val_loader)\r\n",
        "  for batch_idx, (data,targets) in train_loop:\r\n",
        "\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    data= data.to(device=device)\r\n",
        "    targets= targets.to(device=device)\r\n",
        "\r\n",
        "    # FORWARD PROP\r\n",
        "\r\n",
        "    scores= model(data)\r\n",
        "    train_loss= Loss(scores, targets)\r\n",
        "    train_losses.append(train_loss.item())\r\n",
        "\r\n",
        "    # BACKWARD PROP\r\n",
        "    optimizer.zero_grad()\r\n",
        "    train_loss.backward()\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    train_acc= check_accuracy(scores,targets)\r\n",
        "\r\n",
        "    kbar_train.update(batch_idx, values=[(\"loss\", train_loss.item()), (\"accuracy\", train_acc.item())])\r\n",
        "\r\n",
        "  kbar_train.update(train_per_epoch, values=None)\r\n",
        "### VALIDATION\r\n",
        "\r\n",
        "  kbar_val= pkbar.Kbar(target= val_per_epoch, epoch=epoch, num_epochs=num_epochs)\r\n",
        "\r\n",
        "\r\n",
        "  for batch_idx, (data, targets) in val_loop:\r\n",
        "\r\n",
        "    val_losses=[]\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    \r\n",
        "    data= data.to(device=device)\r\n",
        "    targets= targets.to(device=device)\r\n",
        "    scores= model(data)\r\n",
        "    val_loss= Loss(scores, targets)\r\n",
        "    val_losses.append(val_loss.item())\r\n",
        "    val_acc= check_accuracy(scores,targets)\r\n",
        "\r\n",
        "    kbar_val.update(batch_idx, values=[(\"val_loss\", val_loss.item()), (\"val_accuracy\", val_acc.item())])\r\n",
        "\r\n",
        "  if np.mean(val_losses)<min_loss:\r\n",
        "    min_loss= val_loss.item()\r\n",
        "    print('\\nImproved validation loss: {:.4f}'.format(val_loss.item()))\r\n",
        "    print('Saving the model to {}\\n'.format(check_pt_file))\r\n",
        "    save_checkpoint(model, optimizer, check_pt_file)\r\n",
        "    \r\n",
        "  kbar_val.update(val_per_epoch, values=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_YKfqi6JXq8"
      },
      "source": [
        "def CONFUSION_MATRIX(y_true, y_pred, class_labels, order=False):\r\n",
        "  \r\n",
        "  num_classes= len(class_labels)\r\n",
        "  num_examples= len(y_true)\r\n",
        "\r\n",
        "  if order is False:\r\n",
        "    new_labels= np.arange(num_classes)\r\n",
        "    \r\n",
        "    for i in range(num_examples):\r\n",
        "      y_true[i].item= np.where(class_labels==y_true[i])[0]\r\n",
        "      y_pred[i].item= np.where(class_labels==y_pred[i])[0]\r\n",
        "\r\n",
        "  mat= np.zeros((num_classes,num_classes), dtype=np.int)\r\n",
        "  \r\n",
        "  for i in range(num_examples):\r\n",
        "    true= np.uint8(y_true[i].item())\r\n",
        "    pred= np.uint8(y_pred[i].item())\r\n",
        "\r\n",
        "    mat[true,pred]+=1\r\n",
        "\r\n",
        "  return mat\r\n",
        "\r\n",
        "\r\n",
        "def precision_recall_f1(confusion_matrix):\r\n",
        "\r\n",
        "  num_classes= confusion_matrix.shape[0]\r\n",
        "  precision= np.zeros(num_classes, np.float64)\r\n",
        "  recall= np.zeros(num_classes, np.float64)\r\n",
        "  f1= np.zeros(num_classes, np.float64)\r\n",
        "\r\n",
        "  for i in range(num_classes):\r\n",
        "    \r\n",
        "    precision[i]= confusion_matrix[i,i]/np.sum(confusion_matrix[i])\r\n",
        "    recall[i]= confusion_matrix[i,i]/np.sum(confusion_matrix[:,i])\r\n",
        "    f1[i]= 2*precision[i]*recall[i]/(precision[i]+recall[i])\r\n",
        "\r\n",
        "\r\n",
        "  return precision, recall, f1\r\n",
        "\r\n",
        "\r\n",
        "def Final_Metrics(loader, model, class_labels):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    size= len(class_labels)\r\n",
        "    c_mat= np.zeros((size,size), dtype= np.int)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for x, y in loader:\r\n",
        "            x = x.to(device=device)\r\n",
        "            y = y.to(device=device)\r\n",
        "\r\n",
        "            scores= model(x)\r\n",
        "            _, preds = scores.max(1)\r\n",
        "\r\n",
        "            c_mat+= CONFUSION_MATRIX(y, preds, class_labels, order= True)\r\n",
        "    \r\n",
        "    precision, recall, f1= precision_recall_f1(c_mat)\r\n",
        "\r\n",
        "    return c_mat, np.mean(precision), np.mean(recall), np.mean(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8cRuzw9wVaK"
      },
      "source": [
        "resnet_50, _= load_checkpoint(model, optimizer, check_pt_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqdAZbNtudpl"
      },
      "source": [
        "confusion_matrix, precision, recall, f1= Final_Metrics(test_loader, resnet_50, class_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcVhQQ8Hu5D6"
      },
      "source": [
        "print(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t93P6U8_vqEo"
      },
      "source": [
        "precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31oaOfIKvsnx"
      },
      "source": [
        "recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5f_VjUyvvnR"
      },
      "source": [
        " f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVXI6Yxbvyng"
      },
      "source": [
        "np.sum(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMPXNPnjv02l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}